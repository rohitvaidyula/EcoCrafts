{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2017 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { backend_util, buffer, DataStorage, engine, env, kernel_impls, KernelBackend, util } from '@tensorflow/tfjs-core';\nconst whereImpl = kernel_impls.whereImpl;\nimport { assertNotComplex } from './cpu_util';\nexport class MathBackendCPU extends KernelBackend {\n  constructor() {\n    super();\n    this.blockSize = 48;\n    this.firstUse = true;\n    this.data = new DataStorage(this, engine());\n  }\n  write(values, shape, dtype) {\n    if (this.firstUse) {\n      this.firstUse = false;\n      if (env().get('IS_NODE')) {\n        backend_util.warn('\\n============================\\n' + 'Hi there ðŸ‘‹. Looks like you are running TensorFlow.js in ' + 'Node.js. To speed things up dramatically, install our node ' + 'backend, which binds to TensorFlow C++, by running ' + 'npm i @tensorflow/tfjs-node, ' + 'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' + 'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' + 'suffix for CUDA) at the start of your program. ' + 'Visit https://github.com/tensorflow/tfjs-node for more details.' + '\\n============================');\n      }\n    }\n    const dataId = {};\n    this.data.set(dataId, {\n      values,\n      dtype,\n      refCount: 1\n    });\n    return dataId;\n  }\n  /**\r\n   * Create a data bucket in cpu backend.\r\n   * @param shape Shape of the `TensorInfo`.\r\n   * @param dtype DType of the `TensorInfo`.\r\n   * @param values The value of the `TensorInfo` stored as a flattened array.\r\n   */\n  makeTensorInfo(shape, dtype, values) {\n    let outId;\n    if (dtype === 'string' && values != null && values.length > 0 && util.isString(values[0])) {\n      const encodedValues = values.map(d => util.encodeString(d));\n      outId = this.write(encodedValues, shape, dtype);\n    } else {\n      outId = this.write(values, shape, dtype);\n    }\n    return {\n      dataId: outId,\n      shape,\n      dtype\n    };\n  }\n  /** Increase refCount of a `TensorData`. */\n  incRef(dataId) {\n    const tensorData = this.data.get(dataId);\n    tensorData.refCount++;\n  }\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId) {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n  move(dataId, values, shape, dtype) {\n    this.data.set(dataId, {\n      values,\n      dtype,\n      refCount: 1\n    });\n  }\n  numDataIds() {\n    return this.data.numDataIds();\n  }\n  async read(dataId) {\n    return this.readSync(dataId);\n  }\n  readSync(dataId) {\n    const {\n      dtype,\n      complexTensorInfos\n    } = this.data.get(dataId);\n    if (dtype === 'complex64') {\n      const realValues = this.readSync(complexTensorInfos.real.dataId);\n      const imagValues = this.readSync(complexTensorInfos.imag.dataId);\n      return backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    }\n    return this.data.get(dataId).values;\n  }\n  bufferSync(t) {\n    const data = this.readSync(t.dataId);\n    let decodedData = data;\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        decodedData = data.map(d => util.decodeString(d));\n      } catch (_a) {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return buffer(t.shape, t.dtype, decodedData);\n  }\n  makeOutput(values, shape, dtype) {\n    const dataId = this.write(values, shape, dtype);\n    return engine().makeTensorFromDataId(dataId, shape, dtype, this);\n  }\n  disposeData(dataId) {\n    if (this.data.has(dataId)) {\n      const {\n        complexTensorInfos\n      } = this.data.get(dataId);\n      if (complexTensorInfos != null) {\n        this.disposeData(complexTensorInfos.real.dataId);\n        this.disposeData(complexTensorInfos.imag.dataId);\n      }\n      this.data.delete(dataId);\n    }\n  }\n  disposeIntermediateTensorInfo(tensorInfo) {\n    const dataId = tensorInfo.dataId;\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n      if (tensorData.refCount < 1) {\n        this.disposeData(dataId);\n      }\n    }\n  }\n  async time(f) {\n    const start = util.now();\n    f();\n    const kernelMs = util.now() - start;\n    return {\n      kernelMs\n    };\n  }\n  memory() {\n    return {\n      // Unreliable due to automatic gc. The numbers above are cumulative.\n      unreliable: true,\n      reasons: ['The reported memory is an upper bound. Due to automatic garbage ' + 'collection, the true allocated memory may be less.']\n    };\n  }\n  where(condition) {\n    assertNotComplex([condition], 'where');\n    const condVals = this.readSync(condition.dataId);\n    return whereImpl(condition.shape, condVals);\n  }\n  dispose() {}\n  floatPrecision() {\n    return 32;\n  }\n  /** Returns the smallest representable number.  */\n  epsilon() {\n    return super.epsilon();\n  }\n}","map":null,"metadata":{},"sourceType":"module"}