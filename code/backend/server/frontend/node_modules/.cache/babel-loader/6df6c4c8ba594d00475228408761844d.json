{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Use of this source code is governed by an MIT-style\r\n * license that can be found in the LICENSE file or at\r\n * https://opensource.org/licenses/MIT.\r\n * =============================================================================\r\n */\n/**\r\n * Interfaces and methods for training models using tf.Tensor objects.\r\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from '../backend/tfjs_backend';\nimport { configureCallbacks, standardizeCallbacks } from '../base_callbacks';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { disposeTensorsInLogs } from '../logs';\nimport { range } from '../utils/math_utils';\nexport function checkBatchSize(batchSize) {\n  tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), () => `batchSize is required to be a positive integer, but got ${batchSize}`);\n}\n/**\r\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\r\n *\r\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\r\n *   function and `sliceArraysByIndices()` together.\r\n *\r\n * @param arrays: the input.\r\n * @param start: the starting index (inclusive).\r\n * @param stop: the stopping index (exclusive).\r\n * @returns The result of the slicing. If `arrays` is an `Array` of\r\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\r\n *   in the same way.\r\n */\nexport function sliceArrays(arrays, start, stop) {\n  if (arrays == null) {\n    return [null];\n  } else if (Array.isArray(arrays)) {\n    return arrays.map(array => sliceAlongFirstAxis(array, start, stop - start));\n  } else {\n    // Tensor.\n    return sliceAlongFirstAxis(arrays, start, stop - start);\n  }\n}\n/**\r\n * Slice a Tensor or an Array of Tensors, by random-order indices.\r\n *\r\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\r\n *   function and `sliceArrays()` together.\r\n *\r\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\r\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\r\n *   same fashion.\r\n * @param indices The indices to use for slicing along the first (batch)\r\n *   dimension.\r\n * @returns Result(s) of the slicing.\r\n */\nexport function sliceArraysByIndices(arrays, indices) {\n  return tfc.tidy(() => {\n    if (arrays == null) {\n      return null;\n    } else if (Array.isArray(arrays)) {\n      return arrays.map(array => sliceArraysByIndices(array, indices));\n    } else {\n      // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n      //   tensor1d() calls.\n      return gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n    }\n  });\n}\n/**\r\n * Returns a list of batch indices (tuples of indices).\r\n * @param size: Integer, total size of the data to slice into batches.\r\n * @param batchSize: Integer, batch size.\r\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\r\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\r\n *   that satisfy batchStart <= x < batchEnd.\r\n */\nexport function makeBatches(size, batchSize) {\n  const output = [];\n  let batchStart = 0;\n  let batchEnd = null;\n  while (batchStart < size) {\n    batchEnd = batchStart + batchSize;\n    if (batchEnd >= size) {\n      batchEnd = size;\n    }\n    output.push([batchStart, batchEnd]);\n    batchStart = batchEnd;\n  }\n  return output;\n}\n/**\r\n * Abstract fit function for `f(ins)`.\r\n * @param f A Function returning a list of tensors. For training, this\r\n *   function is expected to perform the updates to the variables.\r\n * @param ins List of tensors to be fed to `f`.\r\n * @param outLabels List of strings, display names of the outputs of `f`.\r\n * @param batchSize Integer batch size or `== null` if unknown. Default : 32.\r\n * @param epochs Number of times to iterate over the data. Default : 1.\r\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\r\n * @param callbacks List of callbacks to be called during training.\r\n * @param valF Function to call for validation.\r\n * @param valIns List of tensors to be fed to `valF`.\r\n * @param shuffle Whether to shuffle the data at the beginning of every\r\n * epoch. Default : true.\r\n * @param callbackMetrics List of strings, the display names of the metrics\r\n *   passed to the callbacks. They should be the concatenation of the\r\n *   display names of the outputs of `f` and the list of display names\r\n *   of the outputs of `valF`.\r\n * @param initialEpoch Epoch at which to start training (useful for\r\n *   resuming a previous training run). Default : 0.\r\n * @param stepsPerEpoch Total number of steps (batches on samples) before\r\n *   declaring one epoch finished and starting the next epoch. Ignored with\r\n *   the default value of `undefined` or `null`.\r\n * @param validationSteps Number of steps to run validation for (only if\r\n *   doing validation from data tensors). Not applicable for tfjs-layers.\r\n * @returns A `History` object.\r\n */\nasync function fitLoop(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n  if (batchSize == null) {\n    batchSize = 32;\n  }\n  if (epochs == null) {\n    epochs = 1;\n  }\n  if (shuffle == null) {\n    shuffle = true;\n  }\n  if (initialEpoch == null) {\n    initialEpoch = 0;\n  }\n  // TODO(cais): Change const to let below when implementing validation.\n  let doValidation = false;\n  if (valF != null && valIns != null) {\n    doValidation = true;\n    // TODO(cais): verbose message.\n  }\n\n  if (validationSteps != null) {\n    doValidation = true;\n    if (stepsPerEpoch == null) {\n      throw new ValueError('Can only use `validationSteps` when doing step-wise training, ' + 'i.e., `stepsPerEpoch` must be set.');\n    }\n  }\n  const numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n  let indexArray;\n  if (numTrainSamples != null) {\n    indexArray = range(0, numTrainSamples);\n  }\n  if (verbose == null) {\n    verbose = 1;\n  }\n  const {\n    callbackList,\n    history\n  } = configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics);\n  callbackList.setModel(model);\n  model.history = history;\n  await callbackList.onTrainBegin();\n  model.stopTraining_ = false;\n  // TODO(cais): Take care of callbacks.validation_data as in PyKeras.\n  // TODO(cais): Pre-convert feeds for performance as in PyKeras.\n  for (let epoch = initialEpoch; epoch < epochs; ++epoch) {\n    await callbackList.onEpochBegin(epoch);\n    const epochLogs = {};\n    if (stepsPerEpoch != null) {\n      throw new NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n    } else {\n      if (shuffle === 'batch') {\n        throw new NotImplementedError('batch shuffling is not implemneted yet');\n      } else if (shuffle) {\n        util.shuffle(indexArray);\n      }\n      // Convert the potentially shuffled indices to Tensor1D, to avoid the\n      // cost of repeated creation of Array1Ds later on.\n      const epochIndexArray1D = tensor1d(indexArray);\n      const batches = makeBatches(numTrainSamples, batchSize);\n      for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n        const batchLogs = {};\n        await callbackList.onBatchBegin(batchIndex, batchLogs);\n        tfc.tidy(() => {\n          const batchStart = batches[batchIndex][0];\n          const batchEnd = batches[batchIndex][1];\n          const batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);\n          batchLogs['batch'] = batchIndex;\n          batchLogs['size'] = batchEnd - batchStart;\n          // TODO(cais): In ins, train flag can be a number, instead of an\n          //   Tensor? Do we need to handle this in tfjs-layers?\n          const insBatch = sliceArraysByIndices(ins, batchIds);\n          const outs = f(insBatch);\n          for (let i = 0; i < outLabels.length; ++i) {\n            const label = outLabels[i];\n            const out = outs[i];\n            batchLogs[label] = out;\n            tfc.keep(out);\n            // TODO(cais): Use scope() to avoid ownership.\n          }\n\n          if (batchIndex === batches.length - 1) {\n            // Last batch.\n            if (doValidation) {\n              const valOuts = model.testLoop(valF, valIns, batchSize);\n              // Porting Notes: In tfjs-layers, valOuts is always an Array.\n              for (let i = 0; i < outLabels.length; ++i) {\n                const label = outLabels[i];\n                const out = valOuts[i];\n                tfc.keep(out);\n                // TODO(cais): Use scope() to avoid ownership.\n                epochLogs['val_' + label] = out;\n              }\n            }\n          }\n        });\n        await callbackList.onBatchEnd(batchIndex, batchLogs);\n        disposeTensorsInLogs(batchLogs);\n        if (model.stopTraining_) {\n          break;\n        }\n        // TODO(cais): return outs as list of Tensor.\n      }\n\n      epochIndexArray1D.dispose();\n    }\n    // TODO(cais): Run validation at the end of the epoch.\n    await callbackList.onEpochEnd(epoch, epochLogs);\n    if (model.stopTraining_) {\n      break;\n    }\n  }\n  await callbackList.onTrainEnd();\n  await model.history.syncData();\n  return model.history;\n}\nexport async function fitTensors(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, x, y, args = {}) {\n  if (model.isTraining) {\n    throw new Error('Cannot start training because another fit() call is ongoing.');\n  }\n  model.isTraining = true;\n  let inputs;\n  let targets;\n  let inputValX;\n  let inputValY;\n  let valX;\n  let valY;\n  let sampleWeights;\n  try {\n    const batchSize = args.batchSize == null ? 32 : args.batchSize;\n    checkBatchSize(batchSize);\n    // Validate user data.\n    // TODO(cais): Support sampleWeight.\n    const checkBatchAxis = false;\n    const standardizedOuts = await model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);\n    inputs = standardizedOuts[0];\n    targets = standardizedOuts[1];\n    sampleWeights = standardizedOuts[2];\n    // Prepare validation data.\n    let doValidation = false;\n    let valIns;\n    if (args.validationData != null && args.validationData.length > 0) {\n      doValidation = true;\n      if (args.validationData.length === 2) {\n        // config.validationData consists of valX and valY.\n        inputValX = args.validationData[0];\n        inputValY = args.validationData[1];\n      } else if (args.validationData.length === 3) {\n        throw new NotImplementedError('validationData including sample weights is not supported yet.');\n      } else {\n        throw new ValueError(`When passing validation data, it must contain 2 (valX, valY) ` + `or 3 (valX, valY, valSampleWeight) items; ` + `${args.validationData} is invalid.`);\n      }\n      const checkBatchAxis = true;\n      const valStandardized = await model.standardizeUserData(inputValX, inputValY, null, /** Unused sample weights. */null, /** Unused class weights. */checkBatchAxis, batchSize);\n      valX = valStandardized[0];\n      valY = valStandardized[1];\n      valIns = valX.concat(valY);\n      // TODO(cais): Add useLearningPhase data properly.\n    } else if (args.validationSplit != null && args.validationSplit > 0 && args.validationSplit < 1) {\n      doValidation = true;\n      // Porting Note: In tfjs-layers, inputs[0] is always a Tensor.\n      const splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n      const originalBatchSize = inputs[0].shape[0];\n      valX = sliceArrays(inputs, splitAt, originalBatchSize);\n      inputs = sliceArrays(inputs, 0, splitAt);\n      valY = sliceArrays(targets, splitAt, originalBatchSize);\n      targets = sliceArrays(targets, 0, splitAt);\n      // TODO(cais): Once sampleWeights becomes available, slice it to get\n      //   valSampleWeights.\n      valIns = valX.concat(valY);\n      // TODO(cais): Add useLearningPhase data properly.\n    } else if (args.validationSteps != null) {\n      doValidation = true;\n      // TODO(cais): Add useLearningPhase.\n    }\n\n    const ins = inputs.concat(targets).concat(sampleWeights);\n    model.checkTrainableWeightsConsistency();\n    // TODO(cais): Handle use_learning_phase and learning_phase?\n    // Porting Note: Here we see a key deviation of tfjs-layers from\n    // Keras.\n    //  Due to the imperative nature of tfjs-layers' backend (tfjs-core),\n    //  we do not construct symbolic computation graphs to embody the\n    //  training process. Instead, we define a function that performs the\n    //  training action. In PyKeras, the data (inputs and targets) are fed\n    //  through graph placeholders. In tfjs-layers, the data are fed as\n    //  function arguments. Since the function are defined below in the\n    //  scope, we don't have equivalents of PyKeras's\n    //  `_make_train_funciton`.\n    const trainFunction = model.makeTrainFunction();\n    const outLabels = model.getDedupedMetricsNames();\n    let valFunction;\n    let callbackMetrics;\n    if (doValidation) {\n      model.makeTestFunction();\n      valFunction = model.testFunction;\n      callbackMetrics = outLabels.slice().concat(outLabels.map(n => 'val_' + n));\n    } else {\n      valFunction = null;\n      valIns = [];\n      callbackMetrics = outLabels.slice();\n    }\n    const callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n    const out = await fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);\n    return out;\n  } finally {\n    model.isTraining = false;\n    // Memory clean up.\n    disposeNewTensors(inputs, x);\n    disposeNewTensors(targets, y);\n    disposeNewTensors(valX, inputValX);\n    disposeNewTensors(valY, inputValY);\n    if (sampleWeights != null) {\n      tfc.dispose(sampleWeights);\n    }\n  }\n  // TODO(cais): Add value to outLabels.\n}\n/**\r\n * Ensure tensors all have a rank of at least 2.\r\n *\r\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\r\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\r\n */\nexport function ensureTensorsRank2OrHigher(tensors) {\n  const outs = [];\n  if (tensors instanceof Tensor) {\n    tensors = [tensors];\n  }\n  // Make Tensors at least 2D.\n  for (let i = 0; i < tensors.length; ++i) {\n    const tensor = tensors[i];\n    if (tensor.rank === 1) {\n      outs.push(expandDims(tensor, 1));\n    } else if (tensor.rank === 0) {\n      throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' + '(scalar).');\n    } else {\n      outs.push(tensor);\n    }\n  }\n  return outs;\n}\n/**\r\n * Compare a set of tensors with a reference (old) set, discard the ones\r\n * in the new set that are not present in the reference set.\r\n *\r\n * This method is used for memory clenaup during calls such as\r\n * LayersModel.fit().\r\n *\r\n * @param tensors New set which may contain Tensors not present in\r\n *   `refTensors`.\r\n * @param refTensors Reference Tensor set.\r\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\nexport function disposeNewTensors(tensors, refTensors) {\n  if (tensors == null) {\n    return;\n  }\n  const oldTensorIds = [];\n  if (refTensors instanceof Tensor) {\n    oldTensorIds.push(refTensors.id);\n  } else if (Array.isArray(refTensors)) {\n    refTensors.forEach(t => oldTensorIds.push(t.id));\n  } else if (refTensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in refTensors) {\n      const oldTensor = refTensors[name];\n      oldTensorIds.push(oldTensor.id);\n    }\n  }\n  const tensorsToDispose = [];\n  if (tensors instanceof Tensor) {\n    if (oldTensorIds.indexOf(tensors.id) === -1) {\n      tensorsToDispose.push(tensors);\n    }\n  } else if (Array.isArray(tensors)) {\n    tensors.forEach(t => {\n      if (oldTensorIds.indexOf(t.id) === -1) {\n        tensorsToDispose.push(t);\n      }\n    });\n  } else if (tensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in tensors) {\n      const tensor = tensors[name];\n      if (oldTensorIds.indexOf(tensor.id) === -1) {\n        tensorsToDispose.push(tensor);\n      }\n    }\n  }\n  tensorsToDispose.forEach(t => {\n    if (!t.isDisposed) {\n      t.dispose();\n    }\n  });\n}","map":null,"metadata":{},"sourceType":"module"}