{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the License);\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an AS IS BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { Softplus } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../utils/unary_utils';\n// mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n// epsilon is the difference between 1.0 and the next representable float.\n// For a single precision 32 bit float this should be 2^-23, see:\n// https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\nconst epsilon = 1.1920928955078125e-7;\nconst threshold = Math.log(epsilon) + 2.0;\nexport const softplus = unaryKernelFunc(Softplus, xi => {\n  // Value above which exp(x) may overflow, but softplus(x) == x\n  // is within machine epsilon.\n  const tooLarge = xi > -threshold;\n  // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n  // is within machine epsilon.\n  const tooSmall = xi < threshold;\n  const expX = Math.exp(xi);\n  let result;\n  if (tooSmall) {\n    result = expX;\n  } else if (tooLarge) {\n    result = xi;\n  } else {\n    result = Math.log(1.0 + expX);\n  }\n  return result;\n});\nexport const softplusConfig = {\n  kernelName: Softplus,\n  backendName: 'cpu',\n  kernelFunc: softplus\n};","map":null,"metadata":{},"sourceType":"module"}