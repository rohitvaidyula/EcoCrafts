{"ast":null,"code":"import { computeStrides, sizeFromShape } from '../util';\n/**\n * Check whether updates.shape = indices.shape[:batchDim] +\n * shape[sliceDim:]\n *\n * @param x The input tensor.\n */\nexport function validateUpdateShape(shape, indices, updates) {\n  const sliceDim = indices.rank > 1 ? indices.shape[indices.rank - 1] : 1;\n  const batchDim = indices.rank > 1 ? indices.rank - 1 : 1;\n  const shapeError = 'Must have updates.shape = indices.shape[:batchDim] + ' + `shape[sliceDim:], got updates.shape: ${updates.shape}` + `, indices.shape: ${indices.shape}, shape: ${shape}` + `, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;\n  if (updates.rank < batchDim) {\n    throw new Error(shapeError + ` update.rank < ${batchDim}. `);\n  }\n  if (shape.length < sliceDim + (updates.rank - batchDim)) {\n    throw new Error(shapeError + ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);\n  }\n  if (updates.rank !== batchDim + shape.length - sliceDim) {\n    throw new Error(shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);\n  }\n  for (let d = 0; d < batchDim; ++d) {\n    if (updates.shape[d] !== indices.shape[d]) {\n      throw new Error(shapeError + ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`);\n    }\n  }\n  for (let d = 0; d < updates.rank - batchDim; ++d) {\n    if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {\n      throw new Error(shapeError + ` updates.shape[${d + batchDim}] (${updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${shape[d + batchDim]})`);\n    }\n  }\n}\n/**\n * Validate scatter nd inputs.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n */\nexport function validateInput(updates, indices, shape) {\n  if (indices.rank < 1) {\n    throw new Error('tf.scatterND() expects the indices to be rank 1 or higher,' + ` but the rank was ${indices.rank}.`);\n  }\n  if (updates.rank < 1) {\n    throw new Error('tf.scatterND() expects the updates to be rank 1 or higher,' + ` but the rank was ${updates.rank}.`);\n  }\n  if (indices.dtype !== 'int32') {\n    throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`);\n  }\n  if (shape.length < 1) {\n    throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`);\n  }\n  if (shape.length === 0) {\n    if (indices.size === 0) {\n      throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`);\n    }\n    if (updates.size === 0) {\n      throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`);\n    }\n  }\n  validateUpdateShape(shape, indices, updates);\n}\n/**\n * Calculate the shape information for the output.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n *\n * @returns ScatterShapeInfo\n */\nexport function calculateShapes(updates, indices, shape) {\n  // Calculate the number of dimensions in indices\n  const indicesRank = indices.shape.length;\n  const sliceRank = indicesRank > 1 ? indices.shape[indicesRank - 1] : 1;\n  // Calculate the number of elements that make up each slice of our updated\n  // tensor. This allows us to work with flattened tensors and copy over whole\n  // slices at a time.\n  const totalNd = shape.length;\n  let sliceSize = 1;\n  for (let i = sliceRank; i < totalNd; ++i) {\n    sliceSize *= shape[i];\n  }\n  const safeSliceDim = sliceRank < 1 ? 1 : sliceRank;\n  const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;\n  const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];\n  const outputSize = sizeFromShape(shape);\n  return {\n    sliceRank,\n    numUpdates,\n    sliceSize,\n    strides,\n    outputSize\n  };\n}","map":null,"metadata":{},"sourceType":"module"}