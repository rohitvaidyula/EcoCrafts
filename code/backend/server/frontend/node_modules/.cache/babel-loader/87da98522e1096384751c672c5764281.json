{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, FusedDepthwiseConv2D, util } from '@tensorflow/tfjs-core';\nimport { DepthwiseConv2DProgram } from '../conv_gpu_depthwise';\nimport { DepthwiseConvPacked2DProgram } from '../conv_packed_gpu_depthwise';\nimport { mapActivationToShaderProgram } from '../kernel_utils/kernel_funcs_utils';\nexport function fusedDepthwiseConv2D(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x,\n    filter,\n    bias,\n    preluActivationWeights\n  } = inputs;\n  const {\n    strides,\n    pad,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n  const intermediates = [];\n  let $dilations = dilations;\n  if ($dilations == null) {\n    $dilations = [1, 1];\n  }\n  util.assert(backend_util.eitherStridesOrDilationsAreOne(strides, $dilations), () => 'Error in depthwiseConv2d: Either strides or dilations must be ' + `1. Got strides ${strides} and dilations '${$dilations}'`);\n  const convInfo = backend_util.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad, dimRoundingMode, true /* depthwise */);\n  const shouldPackDepthwiseConv = env().getBool('WEBGL_PACK_DEPTHWISECONV') && convInfo.strideWidth <= 2 && convInfo.outChannels / convInfo.inChannels === 1;\n  const fusedActivation = activation ? mapActivationToShaderProgram(activation, shouldPackDepthwiseConv) : null;\n  const programInputs = [x, filter];\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n  const hasLeakyreluAlpha = activation === 'leakyrelu';\n  if (hasBias) {\n    programInputs.push(bias);\n  }\n  if (hasPreluActivationWeights) {\n    programInputs.push(preluActivationWeights);\n  }\n  if (hasLeakyreluAlpha) {\n    const $leakyreluAlpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(leakyreluAlpha, 'float32'));\n    programInputs.push($leakyreluAlpha);\n    intermediates.push($leakyreluAlpha);\n  }\n  let program;\n  if (shouldPackDepthwiseConv) {\n    program = new DepthwiseConvPacked2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n  } else {\n    program = new DepthwiseConv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n  }\n  const result = backend.runWebGLProgram(program, programInputs, 'float32');\n  intermediates.forEach(t => backend.disposeIntermediateTensorInfo(t));\n  return result;\n}\nexport const fusedDepthwiseConv2DConfig = {\n  kernelName: FusedDepthwiseConv2D,\n  backendName: 'webgl',\n  kernelFunc: fusedDepthwiseConv2D\n};","map":null,"metadata":{},"sourceType":"module"}