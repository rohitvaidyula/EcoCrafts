{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2019 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport * as tfconv from '@tensorflow/tfjs-converter';\nimport * as tf from '@tensorflow/tfjs-core';\nimport { CLASSES } from './classes';\nconst BASE_PATH = 'https://storage.googleapis.com/tfjs-models/savedmodel/';\nexport { version } from './version';\nexport async function load(config = {}) {\n  if (tf == null) {\n    throw new Error(`Cannot find TensorFlow.js. If you are using a <script> tag, please ` + `also include @tensorflow/tfjs on the page before using this model.`);\n  }\n  const base = config.base || 'lite_mobilenet_v2';\n  const modelUrl = config.modelUrl;\n  if (['mobilenet_v1', 'mobilenet_v2', 'lite_mobilenet_v2'].indexOf(base) === -1) {\n    throw new Error(`ObjectDetection constructed with invalid base model ` + `${base}. Valid names are 'mobilenet_v1',` + ` 'mobilenet_v2' and 'lite_mobilenet_v2'.`);\n  }\n  const objectDetection = new ObjectDetection(base, modelUrl);\n  await objectDetection.load();\n  return objectDetection;\n}\nexport class ObjectDetection {\n  constructor(base, modelUrl) {\n    this.modelPath = modelUrl || `${BASE_PATH}${this.getPrefix(base)}/model.json`;\n  }\n  getPrefix(base) {\n    return base === 'lite_mobilenet_v2' ? `ssd${base}` : `ssd_${base}`;\n  }\n  async load() {\n    this.model = await tfconv.loadGraphModel(this.modelPath);\n    const zeroTensor = tf.zeros([1, 300, 300, 3], 'int32');\n    // Warmup the model.\n    const result = await this.model.executeAsync(zeroTensor);\n    await Promise.all(result.map(t => t.data()));\n    result.map(t => t.dispose());\n    zeroTensor.dispose();\n  }\n  /**\r\n   * Infers through the model.\r\n   *\r\n   * @param img The image to classify. Can be a tensor or a DOM element image,\r\n   * video, or canvas.\r\n   * @param maxNumBoxes The maximum number of bounding boxes of detected\r\n   * objects. There can be multiple objects of the same class, but at different\r\n   * locations. Defaults to 20.\r\n   * @param minScore The minimum score of the returned bounding boxes\r\n   * of detected objects. Value between 0 and 1. Defaults to 0.5.\r\n   */\n  async infer(img, maxNumBoxes, minScore) {\n    const batched = tf.tidy(() => {\n      if (!(img instanceof tf.Tensor)) {\n        img = tf.browser.fromPixels(img);\n      }\n      // Reshape to a single-element batch so we can pass it to executeAsync.\n      return img.expandDims(0);\n    });\n    const height = batched.shape[1];\n    const width = batched.shape[2];\n    // model returns two tensors:\n    // 1. box classification score with shape of [1, 1917, 90]\n    // 2. box location with shape of [1, 1917, 1, 4]\n    // where 1917 is the number of box detectors, 90 is the number of classes.\n    // and 4 is the four coordinates of the box.\n    const result = await this.model.executeAsync(batched);\n    const scores = result[0].dataSync();\n    const boxes = result[1].dataSync();\n    // clean the webgl tensors\n    batched.dispose();\n    tf.dispose(result);\n    const [maxScores, classes] = this.calculateMaxScores(scores, result[0].shape[1], result[0].shape[2]);\n    const prevBackend = tf.getBackend();\n    // run post process in cpu\n    tf.setBackend('cpu');\n    const indexTensor = tf.tidy(() => {\n      const boxes2 = tf.tensor2d(boxes, [result[1].shape[1], result[1].shape[3]]);\n      return tf.image.nonMaxSuppression(boxes2, maxScores, maxNumBoxes, minScore, minScore);\n    });\n    const indexes = indexTensor.dataSync();\n    indexTensor.dispose();\n    // restore previous backend\n    tf.setBackend(prevBackend);\n    return this.buildDetectedObjects(width, height, boxes, maxScores, indexes, classes);\n  }\n  buildDetectedObjects(width, height, boxes, scores, indexes, classes) {\n    const count = indexes.length;\n    const objects = [];\n    for (let i = 0; i < count; i++) {\n      const bbox = [];\n      for (let j = 0; j < 4; j++) {\n        bbox[j] = boxes[indexes[i] * 4 + j];\n      }\n      const minY = bbox[0] * height;\n      const minX = bbox[1] * width;\n      const maxY = bbox[2] * height;\n      const maxX = bbox[3] * width;\n      bbox[0] = minX;\n      bbox[1] = minY;\n      bbox[2] = maxX - minX;\n      bbox[3] = maxY - minY;\n      objects.push({\n        bbox: bbox,\n        class: CLASSES[classes[indexes[i]] + 1].displayName,\n        score: scores[indexes[i]]\n      });\n    }\n    return objects;\n  }\n  calculateMaxScores(scores, numBoxes, numClasses) {\n    const maxes = [];\n    const classes = [];\n    for (let i = 0; i < numBoxes; i++) {\n      let max = Number.MIN_VALUE;\n      let index = -1;\n      for (let j = 0; j < numClasses; j++) {\n        if (scores[i * numClasses + j] > max) {\n          max = scores[i * numClasses + j];\n          index = j;\n        }\n      }\n      maxes[i] = max;\n      classes[i] = index;\n    }\n    return [maxes, classes];\n  }\n  /**\r\n   * Detect objects for an image returning a list of bounding boxes with\r\n   * assocated class and score.\r\n   *\r\n   * @param img The image to detect objects from. Can be a tensor or a DOM\r\n   *     element image, video, or canvas.\r\n   * @param maxNumBoxes The maximum number of bounding boxes of detected\r\n   * objects. There can be multiple objects of the same class, but at different\r\n   * locations. Defaults to 20.\r\n   * @param minScore The minimum score of the returned bounding boxes\r\n   * of detected objects. Value between 0 and 1. Defaults to 0.5.\r\n   */\n  async detect(img, maxNumBoxes = 20, minScore = 0.5) {\n    return this.infer(img, maxNumBoxes, minScore);\n  }\n  /**\r\n   * Dispose the tensors allocated by the model. You should call this when you\r\n   * are done with the model.\r\n   */\n  dispose() {\n    if (this.model != null) {\n      this.model.dispose();\n    }\n  }\n}","map":null,"metadata":{},"sourceType":"module"}