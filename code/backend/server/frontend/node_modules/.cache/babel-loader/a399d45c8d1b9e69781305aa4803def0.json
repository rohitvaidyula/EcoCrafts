{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { ENGINE } from '../engine';\nimport { LeakyRelu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\r\n * Computes leaky rectified linear element-wise.\r\n *\r\n * See\r\n * [http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf](\r\n *     http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf)\r\n *\r\n * ```js\r\n * const x = tf.tensor1d([-1, 2, -3, 4]);\r\n *\r\n * x.leakyRelu(0.1).print();  // or tf.leakyRelu(x, 0.1)\r\n * ```\r\n * @param x The input tensor.\r\n * @param alpha The scaling factor for negative values, defaults to 0.2.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Basic math'}\r\n */\nfunction leakyRelu_(x, alpha = 0.2) {\n  const $x = convertToTensor(x, 'x', 'leakyRelu');\n  const inputs = {\n    x: $x\n  };\n  const attrs = {\n    alpha\n  };\n  return ENGINE.runKernel(LeakyRelu, inputs, attrs);\n}\nexport const leakyRelu = op({\n  leakyRelu_\n});","map":null,"metadata":{},"sourceType":"module"}