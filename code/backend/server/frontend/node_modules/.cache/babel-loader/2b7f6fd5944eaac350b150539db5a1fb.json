{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Use of this source code is governed by an MIT-style\r\n * license that can be found in the LICENSE file or at\r\n * https://opensource.org/licenses/MIT.\r\n * =============================================================================\r\n */\n/**\r\n * Built-in metrics.\r\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { tidy } from '@tensorflow/tfjs-core';\nimport * as K from './backend/tfjs_backend';\nimport { NotImplementedError, ValueError } from './errors';\nimport { categoricalCrossentropy as categoricalCrossentropyLoss, cosineProximity, meanAbsoluteError, meanAbsolutePercentageError, meanSquaredError, sparseCategoricalCrossentropy as sparseCategoricalCrossentropyLoss } from './losses';\nimport { binaryCrossentropy as lossBinaryCrossentropy } from './losses';\nimport { lossesMap } from './losses';\nimport * as util from './utils/generic_utils';\nexport function binaryAccuracy(yTrue, yPred) {\n  return tidy(() => {\n    const threshold = tfc.mul(.5, tfc.onesLike(yPred));\n    const yPredThresholded = K.cast(tfc.greater(yPred, threshold), yTrue.dtype);\n    return tfc.mean(tfc.equal(yTrue, yPredThresholded), -1);\n  });\n}\nexport function categoricalAccuracy(yTrue, yPred) {\n  return tidy(() => K.cast(tfc.equal(tfc.argMax(yTrue, -1), tfc.argMax(yPred, -1)), 'float32'));\n}\nfunction truePositives(yTrue, yPred) {\n  return tidy(() => {\n    return tfc.logicalAnd(yTrue.equal(1), yPred.equal(1)).sum().cast('float32');\n  });\n}\nfunction falseNegatives(yTrue, yPred) {\n  return tidy(() => {\n    return tfc.logicalAnd(yTrue.equal(1), yPred.equal(0)).sum().cast('float32');\n  });\n}\nfunction falsePositives(yTrue, yPred) {\n  return tidy(() => {\n    return tfc.logicalAnd(yTrue.equal(0), yPred.equal(1)).sum().cast('float32');\n  });\n}\nexport function precision(yTrue, yPred) {\n  return tidy(() => {\n    const tp = truePositives(yTrue, yPred);\n    const fp = falsePositives(yTrue, yPred);\n    const denominator = tp.add(fp);\n    return tfc.where(tfc.greater(denominator, 0), tp.div(denominator), 0).cast('float32');\n  });\n}\nexport function recall(yTrue, yPred) {\n  return tidy(() => {\n    const tp = truePositives(yTrue, yPred);\n    const fn = falseNegatives(yTrue, yPred);\n    const denominator = tp.add(fn);\n    return tfc.where(tfc.greater(denominator, 0), tp.div(denominator), 0).cast('float32');\n  });\n}\nexport function binaryCrossentropy(yTrue, yPred) {\n  return lossBinaryCrossentropy(yTrue, yPred);\n}\nexport function sparseCategoricalAccuracy(yTrue, yPred) {\n  if (yTrue.rank === yPred.rank) {\n    yTrue = yTrue.squeeze([yTrue.rank - 1]);\n  }\n  yPred = yPred.argMax(-1);\n  if (yPred.dtype !== yTrue.dtype) {\n    yPred = yPred.asType(yTrue.dtype);\n  }\n  return tfc.equal(yTrue, yPred).asType('float32');\n}\nexport function topKCategoricalAccuracy(yTrue, yPred) {\n  throw new NotImplementedError();\n}\nexport function sparseTopKCategoricalAccuracy(yTrue, yPred) {\n  throw new NotImplementedError();\n}\n// Aliases.\nexport const mse = meanSquaredError;\nexport const MSE = meanSquaredError;\nexport const mae = meanAbsoluteError;\nexport const MAE = meanAbsoluteError;\nexport const mape = meanAbsolutePercentageError;\nexport const MAPE = meanAbsolutePercentageError;\nexport const categoricalCrossentropy = categoricalCrossentropyLoss;\nexport const cosine = cosineProximity;\nexport const sparseCategoricalCrossentropy = sparseCategoricalCrossentropyLoss;\n// TODO(cais, nielsene): Add serialize().\nexport const metricsMap = {\n  binaryAccuracy,\n  categoricalAccuracy,\n  precision,\n  categoricalCrossentropy,\n  sparseCategoricalCrossentropy,\n  mse,\n  MSE,\n  mae,\n  MAE,\n  mape,\n  MAPE,\n  cosine\n};\nexport function get(identifier) {\n  if (typeof identifier === 'string' && identifier in metricsMap) {\n    return metricsMap[identifier];\n  } else if (typeof identifier !== 'string' && identifier != null) {\n    return identifier;\n  } else {\n    throw new ValueError(`Unknown metric ${identifier}`);\n  }\n}\n/**\r\n * Get the shortcut function name.\r\n *\r\n * If the fn name is a string,\r\n *   directly return the string name.\r\n * If the function is included in metricsMap or lossesMap,\r\n *   return key of the map.\r\n *   - If the function relative to multiple keys,\r\n *     return the first found key as the function name.\r\n *   - If the function exists in both lossesMap and metricsMap,\r\n *     search lossesMap first.\r\n * If the function is not included in metricsMap or lossesMap,\r\n *   return the function name.\r\n *\r\n * @param fn loss function, metric function, or short cut name.\r\n * @returns Loss or Metric name in string.\r\n */\nexport function getLossOrMetricName(fn) {\n  util.assert(fn !== null, `Unknown LossOrMetricFn ${fn}`);\n  if (typeof fn === 'string') {\n    return fn;\n  } else {\n    let fnName;\n    for (const key of Object.keys(lossesMap)) {\n      if (lossesMap[key] === fn) {\n        fnName = key;\n        break;\n      }\n    }\n    if (fnName !== undefined) {\n      return fnName;\n    }\n    for (const key of Object.keys(metricsMap)) {\n      if (metricsMap[key] === fn) {\n        fnName = key;\n        break;\n      }\n    }\n    if (fnName !== undefined) {\n      return fnName;\n    }\n    return fn.name;\n  }\n}","map":null,"metadata":{},"sourceType":"module"}