{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Max } from '@tensorflow/tfjs-core';\nimport { backend_util, util } from '@tensorflow/tfjs-core';\nimport { maxImplCPU } from '../kernel_utils/shared';\nimport { maxImpl } from './Max_impl';\nimport { transposeImpl, transposeImplCPU } from './Transpose_impl';\nexport function max(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    reductionIndices,\n    keepDims\n  } = attrs;\n  const xRank = x.shape.length;\n  const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  const maxInputIsTransposed = permutedAxes != null;\n  const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);\n  let maxInput = x;\n  if (maxInputIsTransposed) {\n    if (shouldExecuteOnCPU) {\n      const xTexData = backend.texData.get(maxInput.dataId);\n      const values = xTexData.values;\n      const newShape = new Array(xRank);\n      for (let i = 0; i < newShape.length; i++) {\n        newShape[i] = x.shape[permutedAxes[i]];\n      }\n      const maxInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);\n      maxInput = backend.makeTensorInfo(newShape, x.dtype);\n      const maxInputData = backend.texData.get(maxInput.dataId);\n      maxInputData.values = maxInputValues;\n    } else {\n      maxInput = transposeImpl(x, permutedAxes, backend);\n    }\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n  }\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] = backend_util.computeOutAndReduceShapes(maxInput.shape, axes);\n  let outShape = maxOutShape;\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    outShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n  }\n  let out;\n  if (shouldExecuteOnCPU) {\n    const xTexData = backend.texData.get(maxInput.dataId);\n    const values = xTexData.values;\n    const outValues = maxImplCPU(values, util.sizeFromShape(reduceShape), outShape, x.dtype);\n    out = backend.makeTensorInfo(outShape, x.dtype);\n    const outData = backend.texData.get(out.dataId);\n    outData.values = outValues;\n  } else {\n    out = maxImpl(maxInput, reduceShape, outShape, backend);\n  }\n  if (maxInputIsTransposed) {\n    backend.disposeIntermediateTensorInfo(maxInput);\n  }\n  return out;\n}\nexport const maxConfig = {\n  kernelName: Max,\n  backendName: 'webgl',\n  kernelFunc: max\n};","map":null,"metadata":{},"sourceType":"module"}