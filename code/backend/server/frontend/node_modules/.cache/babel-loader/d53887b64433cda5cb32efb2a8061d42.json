{"ast":null,"code":"import * as losses from './losses';\nimport * as metrics from './metrics';\n/**\r\n * Binary accuracy metric function.\r\n *\r\n * `yTrue` and `yPred` can have 0-1 values. Example:\r\n * ```js\r\n * const x = tf.tensor2d([[1, 1, 1, 1], [0, 0, 0, 0]], [2, 4]);\r\n * const y = tf.tensor2d([[1, 0, 1, 0], [0, 0, 0, 1]], [2, 4]);\r\n * const accuracy = tf.metrics.binaryAccuracy(x, y);\r\n * accuracy.print();\r\n * ```\r\n *\r\n * `yTrue` and `yPred` can also have floating-number values between 0 and 1, in\r\n * which case the values will be thresholded at 0.5 to yield 0-1 values (i.e.,\r\n * a value >= 0.5 and <= 1.0 is interpreted as 1.\r\n * )\r\n * Example:\r\n * ```js\r\n * const x = tf.tensor1d([1, 1, 1, 1, 0, 0, 0, 0]);\r\n * const y = tf.tensor1d([0.2, 0.4, 0.6, 0.8, 0.2, 0.3, 0.4, 0.7]);\r\n * const accuracy = tf.metrics.binaryAccuracy(x, y);\r\n * accuracy.print();\r\n * ```\r\n *\r\n * @param yTrue Binary Tensor of truth.\r\n * @param yPred Binary Tensor of prediction.\r\n * @return Accuracy Tensor.\r\n *\r\n * @doc {heading: 'Metrics', namespace: 'metrics'}\r\n */\nexport function binaryAccuracy(yTrue, yPred) {\n  return metrics.binaryAccuracy(yTrue, yPred);\n}\n/**\r\n * Binary crossentropy metric function.\r\n *\r\n * Example:\r\n * ```js\r\n * const x = tf.tensor2d([[0], [1], [1], [1]]);\r\n * const y = tf.tensor2d([[0], [0], [0.5], [1]]);\r\n * const crossentropy = tf.metrics.binaryCrossentropy(x, y);\r\n * crossentropy.print();\r\n * ```\r\n *\r\n * @param yTrue Binary Tensor of truth.\r\n * @param yPred Binary Tensor of prediction, probabilities for the `1` case.\r\n * @return Accuracy Tensor.\r\n *\r\n * @doc {heading: 'Metrics', namespace: 'metrics'}\r\n */\nexport function binaryCrossentropy(yTrue, yPred) {\n  return metrics.binaryCrossentropy(yTrue, yPred);\n}\n/**\r\n * Sparse categorical accuracy metric function.\r\n *\r\n * Example:\r\n * ```js\r\n *\r\n * const yTrue = tf.tensor1d([1, 1, 2, 2, 0]);\r\n * const yPred = tf.tensor2d(\r\n *      [[0, 1, 0], [1, 0, 0], [0, 0.4, 0.6], [0, 0.6, 0.4], [0.7, 0.3, 0]]);\r\n * const crossentropy = tf.metrics.sparseCategoricalAccuracy(yTrue, yPred);\r\n * crossentropy.print();\r\n * ```\r\n *\r\n * @param yTrue True labels: indices.\r\n * @param yPred Predicted probabilities or logits.\r\n * @returns Accuracy tensor.\r\n *\r\n * @doc {heading: 'Metrics', namespace: 'metrics'}\r\n */\nexport function sparseCategoricalAccuracy(yTrue, yPred) {\n  return metrics.sparseCategoricalAccuracy(yTrue, yPred);\n}\n/**\r\n * Categorical accuracy metric function.\r\n *\r\n * Example:\r\n * ```js\r\n * const x = tf.tensor2d([[0, 0, 0, 1], [0, 0, 0, 1]]);\r\n * const y = tf.tensor2d([[0.1, 0.8, 0.05, 0.05], [0.1, 0.05, 0.05, 0.8]]);\r\n * const accuracy = tf.metrics.categoricalAccuracy(x, y);\r\n * accuracy.print();\r\n * ```\r\n *\r\n * @param yTrue Binary Tensor of truth: one-hot encoding of categories.\r\n * @param yPred Binary Tensor of prediction: probabilities or logits for the\r\n *   same categories as in `yTrue`.\r\n * @return Accuracy Tensor.\r\n *\r\n * @doc {heading: 'Metrics', namespace: 'metrics'}\r\n */\nexport function categoricalAccuracy(yTrue, yPred) {\n  return metrics.categoricalAccuracy(yTrue, yPred);\n}\n/**\r\n * Categorical crossentropy between an output tensor and a target tensor.\r\n *\r\n * @param target A tensor of the same shape as `output`.\r\n * @param output A tensor resulting from a softmax (unless `fromLogits` is\r\n *  `true`, in which case `output` is expected to be the logits).\r\n * @param fromLogits Boolean, whether `output` is the result of a softmax, or is\r\n *   a tensor of logits.\r\n *\r\n * @doc {heading: 'Metrics', namespace: 'metrics'}\r\n */\nexport function categoricalCrossentropy(yTrue, yPred) {\n  return metrics.categoricalCrossentropy(yTrue, yPred);\n}\n/**\r\n * Computes the precision of the predictions with respect to the labels.\r\n *\r\n * Example:\r\n * ```js\r\n * const x = tf.tensor2d(\r\n *    [\r\n *      [0, 0, 0, 1],\r\n *      [0, 1, 0, 0],\r\n *      [0, 0, 0, 1],\r\n *      [1, 0, 0, 0],\r\n *      [0, 0, 1, 0]\r\n *    ]\r\n * );\r\n *\r\n * const y = tf.tensor2d(\r\n *    [\r\n *      [0, 0, 1, 0],\r\n *      [0, 1, 0, 0],\r\n *      [0, 0, 0, 1],\r\n *      [0, 1, 0, 0],\r\n *      [0, 1, 0, 0]\r\n *    ]\r\n * );\r\n *\r\n * const precision = tf.metrics.precision(x, y);\r\n * precision.print();\r\n * ```\r\n *\r\n * @param yTrue The ground truth values. Expected to be contain only 0-1 values.\r\n * @param yPred The predicted values. Expected to be contain only 0-1 values.\r\n * @return Precision Tensor.\r\n *\r\n * @doc {heading: 'Metrics', namespace: 'metrics'}\r\n */\nexport function precision(yTrue, yPred) {\n  return metrics.precision(yTrue, yPred);\n}\n/**\r\n * Computes the recall of the predictions with respect to the labels.\r\n *\r\n * Example:\r\n * ```js\r\n * const x = tf.tensor2d(\r\n *    [\r\n *      [0, 0, 0, 1],\r\n *      [0, 1, 0, 0],\r\n *      [0, 0, 0, 1],\r\n *      [1, 0, 0, 0],\r\n *      [0, 0, 1, 0]\r\n *    ]\r\n * );\r\n *\r\n * const y = tf.tensor2d(\r\n *    [\r\n *      [0, 0, 1, 0],\r\n *      [0, 1, 0, 0],\r\n *      [0, 0, 0, 1],\r\n *      [0, 1, 0, 0],\r\n *      [0, 1, 0, 0]\r\n *    ]\r\n * );\r\n *\r\n * const recall = tf.metrics.recall(x, y);\r\n * recall.print();\r\n * ```\r\n *\r\n * @param yTrue The ground truth values. Expected to be contain only 0-1 values.\r\n * @param yPred The predicted values. Expected to be contain only 0-1 values.\r\n * @return Recall Tensor.\r\n *\r\n * @doc {heading: 'Metrics', namespace: 'metrics'}\r\n */\nexport function recall(yTrue, yPred) {\n  return metrics.recall(yTrue, yPred);\n}\n/**\r\n * Loss or metric function: Cosine proximity.\r\n *\r\n * Mathematically, cosine proximity is defined as:\r\n *   `-sum(l2Normalize(yTrue) * l2Normalize(yPred))`,\r\n * wherein `l2Normalize()` normalizes the L2 norm of the input to 1 and `*`\r\n * represents element-wise multiplication.\r\n *\r\n * ```js\r\n * const yTrue = tf.tensor2d([[1, 0], [1, 0]]);\r\n * const yPred = tf.tensor2d([[1 / Math.sqrt(2), 1 / Math.sqrt(2)], [0, 1]]);\r\n * const proximity = tf.metrics.cosineProximity(yTrue, yPred);\r\n * proximity.print();\r\n * ```\r\n *\r\n * @param yTrue Truth Tensor.\r\n * @param yPred Prediction Tensor.\r\n * @return Cosine proximity Tensor.\r\n *\r\n * @doc {heading: 'Metrics', namespace: 'metrics'}\r\n */\nexport function cosineProximity(yTrue, yPred) {\n  return losses.cosineProximity(yTrue, yPred);\n}\n/**\r\n * Loss or metric function: Mean absolute error.\r\n *\r\n * Mathematically, mean absolute error is defined as:\r\n *   `mean(abs(yPred - yTrue))`,\r\n * wherein the `mean` is applied over feature dimensions.\r\n *\r\n * ```js\r\n * const yTrue = tf.tensor2d([[0, 1], [0, 0], [2, 3]]);\r\n * const yPred = tf.tensor2d([[0, 1], [0, 1], [-2, -3]]);\r\n * const mse = tf.metrics.meanAbsoluteError(yTrue, yPred);\r\n * mse.print();\r\n * ```\r\n *\r\n * @param yTrue Truth Tensor.\r\n * @param yPred Prediction Tensor.\r\n * @return Mean absolute error Tensor.\r\n *\r\n * @doc {heading: 'Metrics', namespace: 'metrics'}\r\n */\nexport function meanAbsoluteError(yTrue, yPred) {\n  return losses.meanAbsoluteError(yTrue, yPred);\n}\n/**\r\n * Loss or metric function: Mean absolute percentage error.\r\n *\r\n * ```js\r\n * const yTrue = tf.tensor2d([[0, 1], [10, 20]]);\r\n * const yPred = tf.tensor2d([[0, 1], [11, 24]]);\r\n * const mse = tf.metrics.meanAbsolutePercentageError(yTrue, yPred);\r\n * mse.print();\r\n * ```\r\n *\r\n * Aliases: `tf.metrics.MAPE`, `tf.metrics.mape`.\r\n *\r\n * @param yTrue Truth Tensor.\r\n * @param yPred Prediction Tensor.\r\n * @return Mean absolute percentage error Tensor.\r\n *\r\n * @doc {heading: 'Metrics', namespace: 'metrics'}\r\n */\nexport function meanAbsolutePercentageError(yTrue, yPred) {\n  return losses.meanAbsolutePercentageError(yTrue, yPred);\n}\nexport function MAPE(yTrue, yPred) {\n  return losses.meanAbsolutePercentageError(yTrue, yPred);\n}\nexport function mape(yTrue, yPred) {\n  return losses.meanAbsolutePercentageError(yTrue, yPred);\n}\n/**\r\n * Loss or metric function: Mean squared error.\r\n *\r\n * ```js\r\n * const yTrue = tf.tensor2d([[0, 1], [3, 4]]);\r\n * const yPred = tf.tensor2d([[0, 1], [-3, -4]]);\r\n * const mse = tf.metrics.meanSquaredError(yTrue, yPred);\r\n * mse.print();\r\n * ```\r\n *\r\n * Aliases: `tf.metrics.MSE`, `tf.metrics.mse`.\r\n *\r\n * @param yTrue Truth Tensor.\r\n * @param yPred Prediction Tensor.\r\n * @return Mean squared error Tensor.\r\n *\r\n * @doc {heading: 'Metrics', namespace: 'metrics'}\r\n */\nexport function meanSquaredError(yTrue, yPred) {\n  return losses.meanSquaredError(yTrue, yPred);\n}\nexport function MSE(yTrue, yPred) {\n  return losses.meanSquaredError(yTrue, yPred);\n}\nexport function mse(yTrue, yPred) {\n  return losses.meanSquaredError(yTrue, yPred);\n}","map":null,"metadata":{},"sourceType":"module"}