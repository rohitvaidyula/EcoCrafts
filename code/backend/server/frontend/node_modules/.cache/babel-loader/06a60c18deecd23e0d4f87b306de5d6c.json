{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2018 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n *\r\n * =============================================================================\r\n */\nimport { env } from '@tensorflow/tfjs-core';\nimport { LazyIterator, OneToManyIterator } from './lazy_iterator';\nimport { StringIterator } from './string_iterator';\nexport class ByteChunkIterator extends LazyIterator {\n  /**\r\n   * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\r\n   *\r\n   * The byte arrays producetd from the ByteChunkIterator on which this is\r\n   * called will be interpreted as concatenated.  No assumptions are made about\r\n   * the boundaries of the incoming chunks, so a multi-byte UTF8 encoding of a\r\n   * character may span the boundary between chunks.  This naturally happens,\r\n   * for instance, when reading fixed-size byte arrays from a file.\r\n   */\n  decodeUTF8() {\n    return new Utf8Iterator(this);\n  }\n}\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on ByteChunkIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// We wanted multiple inheritance, e.g.\n//   class Utf8Iterator extends QueueIterator<string>, StringIterator\n// but the TypeScript mixin approach is a bit hacky, so we take this adapter\n// approach instead.\nclass Utf8Iterator extends StringIterator {\n  constructor(upstream) {\n    super();\n    this.upstream = upstream;\n    this.impl = new Utf8IteratorImpl(upstream);\n  }\n  summary() {\n    return this.impl.summary();\n  }\n  async next() {\n    return this.impl.next();\n  }\n}\n/**\r\n * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\r\n *\r\n * This is tricky because the incoming byte array boundaries may disrupt a\r\n * multi-byte UTF8 character. Thus any incomplete character data at the end of\r\n * a chunk must be carried over and prepended to the next chunk before\r\n * decoding. Luckily with native decoder, TextDecoder in browser and\r\n * string_decoder in node, byte array boundaries are handled automatically.\r\n *\r\n * In the context of an input pipeline for machine learning, UTF8 decoding is\r\n * needed to parse text files containing training examples or prediction\r\n * requests (e.g., formatted as CSV or JSON). We cannot use the built-in\r\n * decoding provided by FileReader.readAsText() because here we are in a\r\n * streaming context, which FileReader does not support.\r\n *\r\n * @param upstream A `LazyIterator` of `Uint8Arrays` containing UTF8-encoded\r\n *   text, which should be interpreted as concatenated.  No assumptions are\r\n *   made about the boundaries of the incoming chunks, so a multi-byte UTF8\r\n *   encoding of a character may span the boundary between chunks.  This\r\n *   naturally happens, for instance, when reading fixed-size byte arrays from a\r\n *   file.\r\n */\nclass Utf8IteratorImpl extends OneToManyIterator {\n  constructor(upstream) {\n    super();\n    this.upstream = upstream;\n    if (env().get('IS_BROWSER')) {\n      this.decoder = new TextDecoder('utf-8');\n    } else {\n      // tslint:disable-next-line:no-require-imports\n      const {\n        StringDecoder\n      } = require('string_decoder');\n      this.decoder = new StringDecoder('utf8');\n    }\n  }\n  summary() {\n    return `${this.upstream.summary()} -> Utf8`;\n  }\n  async pump() {\n    const chunkResult = await this.upstream.next();\n    let chunk;\n    if (chunkResult.done) {\n      return false;\n    } else {\n      chunk = chunkResult.value;\n    }\n    let text;\n    if (env().get('IS_BROWSER')) {\n      text = this.decoder.decode(chunk, {\n        stream: true\n      });\n    } else {\n      text = this.decoder.write(Buffer.from(chunk.buffer));\n    }\n    this.outputQueue.push(text);\n    return true;\n  }\n}","map":null,"metadata":{},"sourceType":"module"}