{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2018 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n *\r\n * =============================================================================\r\n */\n// inspired by https://github.com/maxogden/filereader-stream\nimport { env, util } from '@tensorflow/tfjs-core';\nimport { ByteChunkIterator } from './byte_chunk_iterator';\n/**\r\n * Provide a stream of chunks from a File, Blob, or Uint8Array.\r\n * @param file The source File, Blob or Uint8Array.\r\n * @param options Optional settings controlling file reading.\r\n * @returns a lazy Iterator of Uint8Arrays containing sequential chunks of the\r\n *   input File, Blob or Uint8Array.\r\n */\nexport class FileChunkIterator extends ByteChunkIterator {\n  constructor(file, options = {}) {\n    super();\n    this.file = file;\n    this.options = options;\n    util.assert(file instanceof Uint8Array || (env().get('IS_BROWSER') ? file instanceof File || file instanceof Blob : false), () => 'FileChunkIterator only supports File, Blob and Uint8Array ' + 'right now.');\n    this.offset = options.offset || 0;\n    // default 1MB chunk has tolerable perf on large files\n    this.chunkSize = options.chunkSize || 1024 * 1024;\n  }\n  summary() {\n    return `FileChunks ${this.file}`;\n  }\n  async next() {\n    if (this.offset >= (this.file instanceof Uint8Array ? this.file.byteLength : this.file.size)) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n    const chunk = new Promise((resolve, reject) => {\n      const end = this.offset + this.chunkSize;\n      if (this.file instanceof Uint8Array) {\n        // Note if end > this.uint8Array.byteLength, we just get a small last\n        // chunk.\n        resolve(new Uint8Array(this.file.slice(this.offset, end)));\n      } else {\n        // This branch assumes that this.file type is File or Blob, which\n        // means it is in the browser environment.\n        // TODO(soergel): is this a performance issue?\n        const fileReader = new FileReader();\n        fileReader.onload = event => {\n          let data = fileReader.result;\n          // Not sure we can trust the return type of\n          // FileReader.readAsArrayBuffer See e.g.\n          // https://github.com/node-file-api/FileReader/issues/2\n          if (data instanceof ArrayBuffer) {\n            data = new Uint8Array(data);\n          }\n          if (!(data instanceof Uint8Array)) {\n            return reject(new TypeError('FileReader returned unknown type.'));\n          }\n          resolve(data);\n        };\n        fileReader.onabort = event => {\n          return reject(new Error('Aborted'));\n        };\n        fileReader.onerror = event => {\n          return reject(new Error(event.type));\n        };\n        // TODO(soergel): better handle onabort, onerror\n        // Note if end > this.file.size, we just get a small last chunk.\n        const slice = this.file.slice(this.offset, end);\n        // We can't use readAsText here (even if we know the file is text)\n        // because the slice boundary may fall within a multi-byte character.\n        fileReader.readAsArrayBuffer(slice);\n      }\n      this.offset = end;\n    });\n    return {\n      value: await chunk,\n      done: false\n    };\n  }\n}","map":null,"metadata":{},"sourceType":"module"}