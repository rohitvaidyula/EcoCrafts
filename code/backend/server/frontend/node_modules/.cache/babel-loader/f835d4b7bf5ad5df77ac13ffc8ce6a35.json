{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Use of this source code is governed by an MIT-style\r\n * license that can be found in the LICENSE file or at\r\n * https://opensource.org/licenses/MIT.\r\n * =============================================================================\r\n */\n/* Original source: keras/callbacks.py */\nimport { BaseCallback } from './base_callbacks';\nimport { LayersModel } from './engine/training';\nimport { NotImplementedError } from './errors';\nimport { resolveScalarsInLogs } from './logs';\nexport class Callback extends BaseCallback {\n  constructor() {\n    super(...arguments);\n    /** Instance of `keras.models.Model`. Reference of the model being trained. */\n    this.model = null;\n  }\n  setModel(model) {\n    if (!(model instanceof LayersModel)) {\n      throw new Error('model must be a LayersModel, not some other Container');\n    }\n    this.model = model;\n  }\n}\nfunction less(currVal, prevVal) {\n  return currVal < prevVal;\n}\nfunction greater(currVal, prevVal) {\n  return currVal > prevVal;\n}\n/**\r\n * A Callback that stops training when a monitored quantity has stopped\r\n * improving.\r\n */\nexport class EarlyStopping extends Callback {\n  constructor(args) {\n    super();\n    if (args == null) {\n      args = {};\n    }\n    if (args.restoreBestWeights) {\n      throw new NotImplementedError('restoreBestWeights = True is not implemented in EarlyStopping yet.');\n    }\n    this.monitor = args.monitor || 'val_loss';\n    this.minDelta = Math.abs(args.minDelta || 0);\n    this.patience = args.patience || 0;\n    this.verbose = args.verbose || 0;\n    this.mode = args.mode || 'auto';\n    this.baseline = args.baseline;\n    if (['auto', 'min', 'max'].indexOf(this.mode) === -1) {\n      console.warn(`EarlyStopping mode '${this.mode}' is invalid. ` + `Falling back to mode 'auto'.`);\n      this.mode = 'auto';\n    }\n    if (this.mode === 'min') {\n      this.monitorFunc = less;\n    } else if (this.mode === 'max') {\n      this.monitorFunc = greater;\n    } else {\n      // For mode === 'auto'.\n      if (this.monitor.indexOf('acc') !== -1) {\n        this.monitorFunc = greater;\n      } else {\n        this.monitorFunc = less;\n      }\n    }\n    if (this.monitorFunc === less) {\n      this.minDelta *= -1;\n    }\n  }\n  async onTrainBegin(logs) {\n    this.wait = 0;\n    this.stoppedEpoch = 0;\n    if (this.baseline != null) {\n      this.best = this.baseline;\n    } else {\n      this.best = this.monitorFunc === less ? Infinity : -Infinity;\n    }\n  }\n  async onEpochEnd(epoch, logs) {\n    await resolveScalarsInLogs(logs);\n    const current = this.getMonitorValue(logs);\n    if (current == null) {\n      return;\n    }\n    if (this.monitorFunc(current - this.minDelta, this.best)) {\n      this.best = current;\n      this.wait = 0;\n      // TODO(cais): Logic for restoreBestWeights.\n    } else {\n      this.wait++;\n      if (this.wait >= this.patience) {\n        this.stoppedEpoch = epoch;\n        this.model.stopTraining = true;\n      }\n      // TODO(cais): Logic for restoreBestWeights.\n    }\n  }\n\n  async onTrainEnd(logs) {\n    if (this.stoppedEpoch > 0 && this.verbose) {\n      console.log(`Epoch ${this.stoppedEpoch}: early stopping.`);\n    }\n  }\n  getMonitorValue(logs) {\n    if (logs == null) {\n      logs = {};\n    }\n    const monitorValue = logs[this.monitor];\n    if (monitorValue == null) {\n      console.warn(`Metric for EarlyStopping ${this.monitor} is not available. ` + `Available metrics are: ${Object.keys(logs)}`);\n    }\n    return monitorValue;\n  }\n}\n/**\r\n * Factory function for a Callback that stops training when a monitored\r\n * quantity has stopped improving.\r\n *\r\n * Early stopping is a type of regularization, and protects model against\r\n * overfitting.\r\n *\r\n * The following example based on fake data illustrates how this callback\r\n * can be used during `tf.LayersModel.fit()`:\r\n *\r\n * ```js\r\n * const model = tf.sequential();\r\n * model.add(tf.layers.dense({\r\n *   units: 3,\r\n *   activation: 'softmax',\r\n *   kernelInitializer: 'ones',\r\n *   inputShape: [2]\r\n * }));\r\n * const xs = tf.tensor2d([1, 2, 3, 4], [2, 2]);\r\n * const ys = tf.tensor2d([[1, 0, 0], [0, 1, 0]], [2, 3]);\r\n * const xsVal = tf.tensor2d([4, 3, 2, 1], [2, 2]);\r\n * const ysVal = tf.tensor2d([[0, 0, 1], [0, 1, 0]], [2, 3]);\r\n * model.compile(\r\n *     {loss: 'categoricalCrossentropy', optimizer: 'sgd', metrics: ['acc']});\r\n *\r\n * // Without the EarlyStopping callback, the val_acc value would be:\r\n * //   0.5, 0.5, 0.5, 0.5, ...\r\n * // With val_acc being monitored, training should stop after the 2nd epoch.\r\n * const history = await model.fit(xs, ys, {\r\n *   epochs: 10,\r\n *   validationData: [xsVal, ysVal],\r\n *   callbacks: tf.callbacks.earlyStopping({monitor: 'val_acc'})\r\n * });\r\n *\r\n * // Expect to see a length-2 array.\r\n * console.log(history.history.val_acc);\r\n * ```\r\n *\r\n * @doc {\r\n *   heading: 'Callbacks',\r\n *   namespace: 'callbacks'\r\n * }\r\n */\nexport function earlyStopping(args) {\n  return new EarlyStopping(args);\n}\nexport const callbacks = {\n  earlyStopping\n};","map":null,"metadata":{},"sourceType":"module"}