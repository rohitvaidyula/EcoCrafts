{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2018 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { ENGINE } from './engine';\nimport { env } from './environment';\nimport { setDeprecationWarningFn } from './tensor';\nimport { getTensorsInContainer } from './tensor_util';\n/**\r\n * Enables production mode which disables correctness checks in favor of\r\n * performance.\r\n *\r\n * @doc {heading: 'Environment'}\r\n */\nexport function enableProdMode() {\n  env().set('PROD', true);\n}\n/**\r\n * Enables debug mode which will log information about all executed kernels:\r\n * the elapsed time of the kernel execution, as well as the rank, shape, and\r\n * size of the output tensor.\r\n *\r\n * Debug mode will significantly slow down your application as it will\r\n * download the result of every operation to the CPU. This should not be used in\r\n * production. Debug mode does not affect the timing information of the kernel\r\n * execution as we do not measure download time in the kernel execution time.\r\n *\r\n * See also: `tf.profile`, `tf.memory`.\r\n *\r\n * @doc {heading: 'Environment'}\r\n */\nexport function enableDebugMode() {\n  env().set('DEBUG', true);\n}\n/** Globally disables deprecation warnings */\nexport function disableDeprecationWarnings() {\n  env().set('DEPRECATION_WARNINGS_ENABLED', false);\n  console.warn(`TensorFlow.js deprecation warnings have been disabled.`);\n}\n/** Warn users about deprecated functionality. */\nexport function deprecationWarn(msg) {\n  if (env().getBool('DEPRECATION_WARNINGS_ENABLED')) {\n    console.warn(msg + ' You can disable deprecation warnings with ' + 'tf.disableDeprecationWarnings().');\n  }\n}\nsetDeprecationWarningFn(deprecationWarn);\n/**\r\n * Dispose all variables kept in backend engine.\r\n *\r\n * @doc {heading: 'Environment'}\r\n */\nexport function disposeVariables() {\n  ENGINE.disposeVariables();\n}\n/**\r\n * It returns the global engine that keeps track of all tensors and backends.\r\n *\r\n * @doc {heading: 'Environment'}\r\n */\nexport function engine() {\n  return ENGINE;\n}\n/**\r\n * Returns memory info at the current time in the program. The result is an\r\n * object with the following properties:\r\n *\r\n * - `numBytes`: Number of bytes allocated (undisposed) at this time.\r\n * - `numTensors`: Number of unique tensors allocated.\r\n * - `numDataBuffers`: Number of unique data buffers allocated\r\n *   (undisposed) at this time, which is â‰¤ the number of tensors\r\n *   (e.g. `a.reshape(newShape)` makes a new Tensor that shares the same\r\n *   data buffer with `a`).\r\n * - `unreliable`: True if the memory usage is unreliable. See `reasons` when\r\n *    `unreliable` is true.\r\n * - `reasons`: `string[]`, reasons why the memory is unreliable, present if\r\n *    `unreliable` is true.\r\n *\r\n * WebGL Properties:\r\n * - `numBytesInGPU`: Number of bytes allocated (undisposed) in the GPU only at\r\n *     this time.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Memory'}\r\n */\nexport function memory() {\n  return ENGINE.memory();\n}\n/**\r\n * Executes the provided function `f()` and returns a promise that resolves\r\n * with information about the function's memory use:\r\n * - `newBytes`: the number of new bytes allocated\r\n * - `newTensors`: the number of new tensors created\r\n * - `peakBytes`: the peak number of bytes allocated\r\n * - `kernels`: an array of objects for each kernel involved that reports\r\n * their input and output shapes, number of bytes used, and number of new\r\n * tensors created.\r\n * - `kernelNames`: an array of unique strings with just the names of the\r\n * kernels in the `kernels` array.\r\n *\r\n * ```js\r\n * const profile = await tf.profile(() => {\r\n *   const x = tf.tensor1d([1, 2, 3]);\r\n *   let x2 = x.square();\r\n *   x2.dispose();\r\n *   x2 = x.square();\r\n *   x2.dispose();\r\n *   return x;\r\n * });\r\n *\r\n * console.log(`newBytes: ${profile.newBytes}`);\r\n * console.log(`newTensors: ${profile.newTensors}`);\r\n * console.log(`byte usage over all kernels: ${profile.kernels.map(k =>\r\n * k.totalBytesSnapshot)}`);\r\n * ```\r\n *\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Profile'}\r\n */\nexport function profile(f) {\n  return ENGINE.profile(f);\n}\n/**\r\n * Executes the provided function `fn` and after it is executed, cleans up all\r\n * intermediate tensors allocated by `fn` except those returned by `fn`.\r\n * `fn` must not return a Promise (async functions not allowed). The returned\r\n * result can be a complex object.\r\n *\r\n * Using this method helps avoid memory leaks. In general, wrap calls to\r\n * operations in `tf.tidy` for automatic memory cleanup.\r\n *\r\n * NOTE: Variables do *not* get cleaned up when inside a tidy(). If you want to\r\n * dispose variables, please use `tf.disposeVariables` or call dispose()\r\n * directly on variables.\r\n *\r\n * ```js\r\n * // y = 2 ^ 2 + 1\r\n * const y = tf.tidy(() => {\r\n *   // a, b, and one will be cleaned up when the tidy ends.\r\n *   const one = tf.scalar(1);\r\n *   const a = tf.scalar(2);\r\n *   const b = a.square();\r\n *\r\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\r\n *\r\n *   // The value returned inside the tidy function will return\r\n *   // through the tidy, in this case to the variable y.\r\n *   return b.add(one);\r\n * });\r\n *\r\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\r\n * y.print();\r\n * ```\r\n *\r\n * @param nameOrFn The name of the closure, or the function to execute.\r\n *     If a name is provided, the 2nd argument should be the function.\r\n *     If debug mode is on, the timing and the memory usage of the function\r\n *     will be tracked and displayed on the console using the provided name.\r\n * @param fn The function to execute.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Memory'}\r\n */\nexport function tidy(nameOrFn, fn) {\n  return ENGINE.tidy(nameOrFn, fn);\n}\n/**\r\n * Disposes any `tf.Tensor`s found within the provided object.\r\n *\r\n * @param container an object that may be a `tf.Tensor` or may directly\r\n *     contain `tf.Tensor`s, such as a `Tensor[]` or `{key: Tensor, ...}`. If\r\n *     the object is not a `tf.Tensor` or does not contain `Tensors`, nothing\r\n *     happens. In general it is safe to pass any object here, except that\r\n *     `Promise`s are not supported.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Memory'}\r\n */\nexport function dispose(container) {\n  const tensors = getTensorsInContainer(container);\n  tensors.forEach(tensor => tensor.dispose());\n}\n/**\r\n * Keeps a `tf.Tensor` generated inside a `tf.tidy` from being disposed\r\n * automatically.\r\n *\r\n * ```js\r\n * let b;\r\n * const y = tf.tidy(() => {\r\n *   const one = tf.scalar(1);\r\n *   const a = tf.scalar(2);\r\n *\r\n *   // b will not be cleaned up by the tidy. a and one will be cleaned up\r\n *   // when the tidy ends.\r\n *   b = tf.keep(a.square());\r\n *\r\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\r\n *\r\n *   // The value returned inside the tidy function will return\r\n *   // through the tidy, in this case to the variable y.\r\n *   return b.add(one);\r\n * });\r\n *\r\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\r\n * console.log('y:');\r\n * y.print();\r\n * console.log('b:');\r\n * b.print();\r\n * ```\r\n *\r\n * @param result The tensor to keep from being disposed.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Memory'}\r\n */\nexport function keep(result) {\n  return ENGINE.keep(result);\n}\n/**\r\n * Executes `f()` and returns a promise that resolves with timing\r\n * information.\r\n *\r\n * The result is an object with the following properties:\r\n *\r\n * - `wallMs`: Wall execution time.\r\n * - `kernelMs`: Kernel execution time, ignoring data transfer. If using the\r\n * WebGL backend and the query timer extension is not available, this will\r\n * return an error object.\r\n * - On `WebGL` The following additional properties exist:\r\n *   - `uploadWaitMs`: CPU blocking time on texture uploads.\r\n *   - `downloadWaitMs`: CPU blocking time on texture downloads (readPixels).\r\n *\r\n * ```js\r\n * const x = tf.randomNormal([20, 20]);\r\n * const time = await tf.time(() => x.matMul(x));\r\n *\r\n * console.log(`kernelMs: ${time.kernelMs}, wallTimeMs: ${time.wallMs}`);\r\n * ```\r\n *\r\n * @param f The function to execute and time.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Timing'}\r\n */\nexport function time(f) {\n  return ENGINE.time(f);\n}\n/**\r\n * Sets the backend (cpu, webgl, wasm, etc) responsible for creating tensors and\r\n * executing operations on those tensors. Returns a promise that resolves\r\n * to a boolean if the backend initialization was successful.\r\n *\r\n * Note this disposes the current backend, if any, as well as any tensors\r\n * associated with it. A new backend is initialized, even if it is of the\r\n * same type as the previous one.\r\n *\r\n * @param backendName The name of the backend. Currently supports\r\n *     `'webgl'|'cpu'` in the browser, `'tensorflow'` under node.js\r\n *     (requires tfjs-node), and `'wasm'` (requires tfjs-backend-wasm).\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\nexport function setBackend(backendName) {\n  return ENGINE.setBackend(backendName);\n}\n/**\r\n * Returns a promise that resolves when the currently selected backend (or the\r\n * highest priority one) has initialized. Await this promise when you are using\r\n * a backend that has async initialization.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\nexport function ready() {\n  return ENGINE.ready();\n}\n/**\r\n * Returns the current backend name (cpu, webgl, etc). The backend is\r\n * responsible for creating tensors and executing operations on those tensors.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\nexport function getBackend() {\n  return ENGINE.backendName;\n}\n/**\r\n * Removes a backend and the registered factory.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\nexport function removeBackend(name) {\n  ENGINE.removeBackend(name);\n}\n/**\r\n * Finds the backend registered under the provided name. Returns null if the\r\n * name is not in the registry, or the registration hasn't finished yet.\r\n */\nexport function findBackend(name) {\n  return ENGINE.findBackend(name);\n}\n/**\r\n * Finds the backend factory registered under the provided name. Returns a\r\n * function that produces a new backend when called. Returns null if the name\r\n * is not in the registry.\r\n */\nexport function findBackendFactory(name) {\n  return ENGINE.findBackendFactory(name);\n}\n/**\r\n * Registers a global backend. The registration should happen when importing\r\n * a module file (e.g. when importing `backend_webgl.ts`), and is used for\r\n * modular builds (e.g. custom tfjs bundle with only webgl support).\r\n *\r\n * @param factory The backend factory function. When called, it should\r\n * return a backend instance, or a promise of an instance.\r\n * @param priority The priority of the backend (higher = more important).\r\n *     In case multiple backends are registered, the priority is used to find\r\n *     the best backend. Defaults to 1.\r\n * @return False if there is already a registered backend under this name, true\r\n *     if not.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\nexport function registerBackend(name, factory, priority = 1) {\n  return ENGINE.registerBackend(name, factory, priority);\n}\n/**\r\n * Gets the current backend. If no backends have been initialized, this will\r\n * attempt to initialize the best backend. Will throw an error if the highest\r\n * priority backend has async initialization, in which case, you should call\r\n * 'await tf.ready()' before running other code.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\nexport function backend() {\n  return ENGINE.backend;\n}\n/**\r\n * Sets the global platform.\r\n *\r\n * @param platformName The name of this platform.\r\n * @param platform A platform implementation.\r\n */\nexport function setPlatform(platformName, platform) {\n  env().setPlatform(platformName, platform);\n}","map":null,"metadata":{},"sourceType":"module"}