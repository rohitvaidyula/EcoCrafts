{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Use of this source code is governed by an MIT-style\r\n * license that can be found in the LICENSE file or at\r\n * https://opensource.org/licenses/MIT.\r\n * =============================================================================\r\n */\n/* Original source keras/models.py */\nimport { dispose, io, serialization, util } from '@tensorflow/tfjs-core';\nimport { getUid } from './backend/state';\nimport { Input } from './engine/input_layer';\nimport { getSourceInputs, Node } from './engine/topology';\nimport { LayersModel } from './engine/training';\nimport { NotImplementedError, RuntimeError, ValueError } from './errors';\nimport { deserialize } from './layers/serialization';\nimport * as generic_utils from './utils/generic_utils';\nimport { convertPythonicToTs } from './utils/serialization_utils';\nimport { getExactlyOneShape } from './utils/types_utils';\n/**\r\n * Parses a JSON model configuration file and returns a model instance.\r\n *\r\n * ```js\r\n * // This example shows how to serialize a model using `toJSON()` and\r\n * // deserialize it as another model using `tf.models.modelFromJSON()`.\r\n * // Note: this example serializes and deserializes only the topology\r\n * // of the model; the weights of the loaded model will be different\r\n * // from those of the the original model, due to random weight\r\n * // initialization.\r\n * // To load the topology and weights of a model, use `tf.loadLayersModel()`.\r\n * const model1 = tf.sequential();\r\n * model1.add(tf.layers.repeatVector({inputShape: [2], n: 4}));\r\n * // Serialize `model1` as a JSON object.\r\n * const model1JSON = model1.toJSON(null, false);\r\n * model1.summary();\r\n *\r\n * const model2 = await tf.models.modelFromJSON(model1JSON);\r\n * model2.summary();\r\n * ```\r\n *\r\n *  @param modelAndWeightsConfig JSON object or string encoding a model and\r\n *       weights configuration. It can also be only the topology JSON of the\r\n *       model, in which case the weights will not be loaded.\r\n *  @param custom_objects Optional dictionary mapping names\r\n *       (strings) to custom classes or functions to be\r\n *       considered during deserialization.\r\n * @returns A TensorFlow.js Layers `tf.LayersModel` instance (uncompiled).\r\n */\nexport async function modelFromJSON(modelAndWeightsConfig, customObjects) {\n  if (!('modelTopology' in modelAndWeightsConfig)) {\n    modelAndWeightsConfig = {\n      modelTopology: modelAndWeightsConfig\n    };\n  }\n  modelAndWeightsConfig = modelAndWeightsConfig;\n  let modelTopology = modelAndWeightsConfig.modelTopology;\n  if (modelTopology['model_config'] != null) {\n    // If the model-topology JSON contains a 'model_config' field, then it is\n    // a full model JSON (e.g., from `keras.Model.save()`), which contains\n    // not only the model's architecture in its 'model_config' field, but\n    // additional information such as the model's optimizer. We use only the\n    // 'model_config' field currently.\n    modelTopology = modelTopology['model_config'];\n  }\n  const tsConfig = convertPythonicToTs(modelTopology);\n  const model = deserialize(tsConfig, customObjects);\n  if (modelAndWeightsConfig.weightsManifest != null) {\n    // Load the weight values keyed by the original tensor names in the model\n    // file that was loaded.  These should match the keys of the weight\n    // manifest.\n    const weightValues = await io.loadWeights(modelAndWeightsConfig.weightsManifest, modelAndWeightsConfig.pathPrefix, model.weights.map(weight => weight.originalName));\n    // Map the weights to the unique tensor names generated during model loading\n    const uniqueWeightValues = {};\n    for (const weight of model.weights) {\n      uniqueWeightValues[weight.originalName] = weightValues[weight.originalName];\n    }\n    model.loadWeights(uniqueWeightValues);\n    // Dispose temporary weight values.\n    dispose(weightValues);\n  }\n  return model;\n}\n/**\r\n * Load a model, including its topology and optionally weights.  See the\r\n * Tutorial named \"How to import a Keras Model\" for usage examples.\r\n *\r\n * Example 1: Save `model`'s topology and weights to browser [local\r\n * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\r\n * then load it back.\r\n *\r\n * ```js\r\n * const model = tf.sequential(\r\n *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\r\n * console.log('Prediction from original model:');\r\n * model.predict(tf.ones([1, 3])).print();\r\n *\r\n * const saveResults = await model.save('localstorage://my-model-1');\r\n *\r\n * const loadedModel = await tf.loadLayersModel('localstorage://my-model-1');\r\n * console.log('Prediction from loaded model:');\r\n * loadedModel.predict(tf.ones([1, 3])).print();\r\n * ```\r\n *\r\n * Example 2. Saving `model`'s topology and weights to browser\r\n * [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API);\r\n * then load it back.\r\n *\r\n * ```js\r\n * const model = tf.sequential(\r\n *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\r\n * console.log('Prediction from original model:');\r\n * model.predict(tf.ones([1, 3])).print();\r\n *\r\n * const saveResults = await model.save('indexeddb://my-model-1');\r\n *\r\n * const loadedModel = await tf.loadLayersModel('indexeddb://my-model-1');\r\n * console.log('Prediction from loaded model:');\r\n * loadedModel.predict(tf.ones([1, 3])).print();\r\n * ```\r\n *\r\n * Example 3. Load a model from user-selected files from HTML\r\n * [file input\r\n * elements](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/input/file).\r\n *\r\n * ```js\r\n * // Note: this code snippet will not work without the HTML elements in the\r\n * //   page\r\n * const jsonUpload = document.getElementById('json-upload');\r\n * const weightsUpload = document.getElementById('weights-upload');\r\n *\r\n * const model = await tf.loadLayersModel(\r\n *     tf.io.browserFiles([jsonUpload.files[0], weightsUpload.files[0]]));\r\n * ```\r\n *\r\n * Example 4. Load a model from an HTTP server.\r\n *\r\n * ```js\r\n * const model = await\r\n *     tf.loadLayersModel('https://storage.googleapis.com/tfjs-models/tfjs/iris_v1/model.json');\r\n * model.summary();\r\n * ```\r\n *\r\n * @param pathOrIOHandler Can be either of the two formats\r\n *   1. A string path to the `ModelAndWeightsConfig` JSON describing\r\n *      the model in the canonical TensorFlow.js format. This path will be\r\n *      interpreted as a relative HTTP path, to which `fetch` will be used to\r\n *      request the model topology and weight manifest JSON.\r\n *      The content of the JSON file is assumed to be a JSON object with the\r\n *      following fields and values:\r\n *      - 'modelTopology': A JSON object that can be either of:\r\n *        1. a model architecture JSON consistent with the format of the return\r\n *            value of `keras.Model.to_json()`\r\n *        2. a full model JSON in the format of `keras.models.save_model()`.\r\n *      - 'weightsManifest': A TensorFlow.js weights manifest.\r\n *      See the Python converter function `save_model()` for more details.\r\n *      It is also assumed that model weights can be accessed from relative\r\n *      paths described by the `paths` fields in weights manifest.\r\n *   2. An `tf.io.IOHandler` object that loads model artifacts with its `load`\r\n *      method.\r\n * @param options Optional configuration arguments for the model loading,\r\n *   including:\r\n *   - `strict`: Require that the provided weights exactly match those required\r\n *     by the layers.  Default true.  Passing false means that both extra\r\n *     weights and missing weights will be silently ignored.\r\n *   - `onProgress`: A progress callback of the form:\r\n *     `(fraction: number) => void`. This callback can be used to monitor the\r\n *     model-loading process.\r\n * @returns A `Promise` of `tf.LayersModel`, with the topology and weights\r\n *     loaded.\r\n */\nexport async function loadLayersModelInternal(pathOrIOHandler, options) {\n  if (options == null) {\n    options = {};\n  }\n  if (typeof pathOrIOHandler === 'string') {\n    const handlers = io.getLoadHandlers(pathOrIOHandler, options);\n    if (handlers.length === 0) {\n      // For backward compatibility: if no load handler can be found,\n      // assume it is a relative http path.\n      // TODO(cais): Reformat the args into a single `LoadOptions` once the core\n      // is refactored.\n      handlers.push(io.browserHTTPRequest(pathOrIOHandler, options));\n    } else if (handlers.length > 1) {\n      throw new ValueError(`Found more than one (${handlers.length}) load handlers for ` + `URL '${pathOrIOHandler}'`);\n    }\n    pathOrIOHandler = handlers[0];\n  }\n  return loadLayersModelFromIOHandler(pathOrIOHandler, undefined, options);\n}\n/**\r\n * Load a model and optionally its weights, using an IOHandler object.\r\n *\r\n * @param handler The instance of `IOHandler` to be used during the model\r\n *   loading.\r\n * @param customObjects Any optional custom objects to be used during model\r\n *   loading.\r\n * @param strict Whether the weight loading will be done in strict mode.\r\n *   Default: `true`.\r\n */\nexport async function loadLayersModelFromIOHandler(handler, customObjects, options) {\n  if (options == null) {\n    options = {};\n  }\n  if (handler.load == null) {\n    throw new ValueError('Cannot proceed with model loading because the IOHandler provided ' + 'does not have the `load` method implemented.');\n  }\n  const artifacts = await handler.load();\n  let modelTopology = artifacts.modelTopology;\n  if (modelTopology['model_config'] != null) {\n    modelTopology = modelTopology['model_config'];\n  }\n  const strict = options.strict == null ? true : options.strict;\n  // If weights are provided and the weight-loading mode is strict, use\n  // fast weight initialization. This skips costly initializers such as\n  // 'orthogonal' and saves unnecessary computation in cases where\n  // the initialized weight values will immediately be overwritten by\n  // loaded weight values.\n  const fastWeightInit = artifacts.weightData != null && artifacts.weightSpecs != null && strict;\n  const model = deserialize(convertPythonicToTs(modelTopology), customObjects, fastWeightInit);\n  const trainingConfig = artifacts.trainingConfig;\n  if (trainingConfig != null) {\n    model.loadTrainingConfig(trainingConfig);\n  }\n  if (artifacts.userDefinedMetadata != null) {\n    model.setUserDefinedMetadata(artifacts.userDefinedMetadata);\n  }\n  // If weightData is present, load the weights into the model.\n  if (artifacts.weightData != null) {\n    // Loading weights requires weightSpecs.\n    if (artifacts.weightSpecs == null) {\n      throw new ValueError('LayersModel artifacts contains weight data, but not weight specs. ' + 'Therefore loading of weights cannot proceed.');\n    }\n    const {\n      modelWeights,\n      optimizerWeights\n    } = decodeModelAndOptimizerWeights(artifacts.weightData, artifacts.weightSpecs);\n    model.loadWeights(modelWeights, strict);\n    if (model.optimizer != null && optimizerWeights.length > 0) {\n      await model.optimizer.setWeights(optimizerWeights);\n    }\n    // Dispose temporary weight values.\n    dispose(modelWeights);\n    dispose(optimizerWeights.map(w => w.tensor));\n  }\n  return model;\n}\nfunction decodeModelAndOptimizerWeights(buffer, specs) {\n  const name2Tensor = io.decodeWeights(buffer, specs);\n  const modelWeights = {};\n  const optimizerWeights = [];\n  specs.forEach(spec => {\n    if (spec.group === 'optimizer') {\n      optimizerWeights.push({\n        name: spec.name,\n        tensor: name2Tensor[spec.name]\n      });\n    } else {\n      modelWeights[spec.name] = name2Tensor[spec.name];\n    }\n  });\n  return {\n    modelWeights,\n    optimizerWeights\n  };\n}\n/**\r\n * A model with a stack of layers, feeding linearly from one to the next.\r\n *\r\n * `tf.sequential` is a factory function that creates an instance of\r\n * `tf.Sequential`.\r\n *\r\n * ```js\r\n *  // Define a model for linear regression.\r\n *  const model = tf.sequential();\r\n *  model.add(tf.layers.dense({units: 1, inputShape: [1]}));\r\n *\r\n *  // Prepare the model for training: Specify the loss and the optimizer.\r\n *  model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\r\n *\r\n *  // Generate some synthetic data for training.\r\n *  const xs = tf.tensor2d([1, 2, 3, 4], [4, 1]);\r\n *  const ys = tf.tensor2d([1, 3, 5, 7], [4, 1]);\r\n *\r\n *  // Train the model using the data then do inference on a data point the\r\n *  // model hasn't seen:\r\n *  await model.fit(xs, ys);\r\n *  model.predict(tf.tensor2d([5], [1, 1])).print();\r\n * ```\r\n *\r\n * @doc {heading: 'Models', subheading: 'Classes'}\r\n */\nexport class Sequential extends LayersModel {\n  constructor(args) {\n    super({\n      inputs: [],\n      outputs: []\n    });\n    args = args || {};\n    this.trainable = true;\n    this.built = false;\n    // Set model name.\n    this.name = args.name != null ? args.name : getUid('sequential_');\n    // Add to the model any layers passed to the constructor.\n    if (args.layers != null) {\n      for (const layer of args.layers) {\n        this.add(layer);\n      }\n    }\n  }\n  // Helper function to Sequential.add  Throws if the new output shape will be\n  // invalid.\n  checkShape(layer) {\n    const shape = layer.inboundNodes[0].outputTensors[0].shape;\n    if (shape.some(x => x < 0)) {\n      throw new ValueError('Negative dimension size caused by adding layer ' + `${layer.name} with input shape [` + `${layer.inboundNodes[0].inputTensors[0].shape}]`);\n    }\n  }\n  /**\r\n   * Adds a layer instance on top of the layer stack.\r\n   *\r\n   * ```js\r\n   *  const model = tf.sequential();\r\n   *  model.add(tf.layers.dense({units: 8, inputShape: [1]}));\r\n   *  model.add(tf.layers.dense({units: 4, activation: 'relu6'}));\r\n   *  model.add(tf.layers.dense({units: 1, activation: 'relu6'}));\r\n   *  // Note that the untrained model is random at this point.\r\n   *  model.predict(tf.randomNormal([10, 1])).print();\r\n   * ```\r\n   * @param layer Layer instance.\r\n   *\r\n   * @exception ValueError In case the `layer` argument does not know its\r\n   * input shape.\r\n   * @exception ValueError In case the `layer` argument has multiple output\r\n   *   tensors, or is already connected somewhere else (forbidden in\r\n   *   `Sequential` models).\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n  add(layer) {\n    const isLayerModelInstance = layer instanceof Sequential || layer instanceof LayersModel;\n    let modelLayer;\n    if (isLayerModelInstance) {\n      modelLayer = layer;\n      if (modelLayer.outputs.length !== 1) {\n        throw new ValueError('All layers in a Sequential model ' + 'should have a single output tensor. ' + 'For multi-output layers, ' + 'use the functional API.');\n      }\n      if (modelLayer.inputs.length !== 1) {\n        throw new ValueError('All layers in a Sequential model ' + 'should have a single input tensor. ' + 'For multi-input layers, ' + 'use the functional API.');\n      }\n    }\n    if (this.outputs.length === 0) {\n      // first layer in model: check that it is an input layer\n      if (layer.inboundNodes.length === 0) {\n        // create an input layer\n        if (layer.batchInputShape == null) {\n          throw new ValueError('The first layer in a Sequential model must ' + 'get an `inputShape` or `batchInputShape` argument.');\n        }\n        // Instantiate the input layer.\n        const x = Input({\n          batchShape: layer.batchInputShape,\n          dtype: layer.dtype,\n          name: layer.name + '_input'\n        });\n        // This will build the current layer and create the node connecting\n        // the current layer to the input layer we just created.\n        layer.apply(x);\n      }\n      if (isLayerModelInstance) {\n        this.outputs = modelLayer.outputs;\n        this.inputs = modelLayer.inputs;\n      } else {\n        if (layer.inboundNodes.length !== 1) {\n          throw new ValueError('A layer added to a Sequential model must not already be ' + `connected somewhere else. LayersModel received layer ${layer.name} ` + `which has ${layer.inboundNodes.length} pre-existing inbound ` + 'connections.');\n        }\n        if (layer.inboundNodes[0].outputTensors.length !== 1) {\n          throw new ValueError('All layers in a Sequential model ' + 'should have a single output tensor. ' + 'For multi-output layers, ' + 'use the functional API.');\n        }\n        this.checkShape(layer);\n        this.outputs = [layer.inboundNodes[0].outputTensors[0]];\n        this.inputs = getSourceInputs(this.outputs[0]);\n      }\n      this.inboundNodes = [];\n      // We create an input node, which we will keep updated\n      // as we add more layers.\n      // (This call has side effects.)\n      // tslint:disable-next-line:no-unused-expression\n      new Node({\n        outboundLayer: this,\n        inboundLayers: [],\n        nodeIndices: [],\n        tensorIndices: [],\n        inputTensors: this.inputs,\n        outputTensors: this.outputs,\n        // no model-level masking for now\n        inputMasks: generic_utils.pyListRepeat(null, this.inputs.length),\n        outputMasks: [null],\n        inputShapes: this.inputs.map(x => x.shape),\n        outputShapes: this.outputs[0].shape\n      });\n    } else {\n      const outputTensor = layer.apply(this.outputs[0]);\n      if (Array.isArray(outputTensor)) {\n        throw new TypeError('All layers in a Sequential model ' + 'should have a single output tensor. ' + 'For multi-output layers, ' + 'use the functional API.');\n      }\n      this.checkShape(layer);\n      this.outputs = [outputTensor];\n      // update self.inbound_nodes\n      this.inboundNodes[0].outputTensors = this.outputs;\n      this.inboundNodes[0].outputShapes = [this.outputs[0].shape];\n    }\n    this.layers.push(layer);\n    this.built = false;\n  }\n  /**\r\n   * Removes the last layer in the model.\r\n   *\r\n   * @exception TypeError if there are no layers in the model.\r\n   */\n  pop() {\n    if (this.layers.length === 0) {\n      throw new TypeError('There are no layers in the model.');\n    }\n    this.layers.pop();\n    if (this.layers.length === 0) {\n      this.outputs = [];\n      this.inboundNodes = [];\n      this.outboundNodes = [];\n    } else {\n      const lastLayerIndex = this.layers.length - 1;\n      this.layers[lastLayerIndex].outboundNodes = [];\n      this.outputs = [this.layers[lastLayerIndex].output];\n      // update self.inbound_nodes\n      this.inboundNodes[0].outputTensors = this.outputs;\n      this.inboundNodes[0].outputShapes = [this.outputs[0].shape];\n    }\n  }\n  call(inputs, kwargs) {\n    if (this.model == null) {\n      this.build();\n    }\n    return this.model.call(inputs, kwargs);\n  }\n  build(inputShape) {\n    // Call `getExactlyOneShape` without using its return value,\n    // to verify that exactly one input shape is provided.\n    getExactlyOneShape(inputShape);\n    if (this.inputs.length === 0 || this.outputs.length === 0) {\n      throw new TypeError('Sequential model cannot be built: model is empty.' + ' Add some layers first.');\n    }\n    // actually create the model\n    this.model = new LayersModel({\n      inputs: this.inputs,\n      outputs: this.outputs[0],\n      name: this.name + '_model'\n    });\n    this.model.trainable = this.trainable;\n    // mirror model attributes\n    this.supportsMasking = this.model.supportsMasking;\n    // TODO(michaelterry): Add caches\n    this.inputLayers = this.model.inputLayers;\n    this.inputLayersNodeIndices = this.model.inputLayersNodeIndices;\n    this.inputLayersTensorIndices = this.model.inputLayersTensorIndices;\n    this.outputLayers = this.model.outputLayers;\n    this.outputLayersNodeIndices = this.model.outputLayersNodeIndices;\n    this.outputLayersTensorIndices = this.model.outputLayersTensorIndices;\n    this.nodesByDepth = this.model.nodesByDepth;\n    this.containerNodes = this.model.containerNodes;\n    this.outputNames = this.model.outputNames;\n    this.inputNames = this.model.inputNames;\n    // TODO(michaelterry): Add feedInputNames, feedInputs, if needed.\n    // TODO(michaelterry): Add callbackModel if needed.\n    this.built = true;\n  }\n  countParams() {\n    if (!this.built) {\n      this.build();\n    }\n    return super.countParams();\n  }\n  /**\r\n   * Print a text summary of the Sequential model's layers.\r\n   *\r\n   * The summary includes\r\n   * - Name and type of all layers that comprise the model.\r\n   * - Output shape(s) of the layers\r\n   * - Number of weight parameters of each layer\r\n   * - The total number of trainable and non-trainable parameters of the\r\n   * model.\r\n   *\r\n   * ```js\r\n   * const model = tf.sequential();\r\n   * model.add(\r\n   *     tf.layers.dense({units: 100, inputShape: [10], activation: 'relu'}));\r\n   * model.add(tf.layers.dense({units: 1, activation: 'sigmoid'}));\r\n   *\r\n   * model.summary();\r\n   * ```\r\n   *\r\n   * @param lineLength Custom line length, in number of characters.\r\n   * @param positions Custom widths of each of the columns, as either\r\n   *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number\r\n   *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to\r\n   *   right-most (i.e., ending) position of a column.\r\n   * @param printFn Custom print function. Can be used to replace the default\r\n   *   `console.log`. For example, you can use `x => {}` to mute the printed\r\n   *   messages in the console.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n  summary(lineLength, positions, printFn = console.log) {\n    if (!this.built) {\n      this.build();\n    }\n    super.summary(lineLength, positions, printFn);\n  }\n  /**\r\n   * Sets the weights of the model.\r\n   *\r\n   * @param weights Should be a list of Tensors with shapes and types matching\r\n   *   the output of `model.getWeights()`.\r\n   */\n  setWeights(weights) {\n    if (this.model == null) {\n      this.build();\n    }\n    this.model.setWeights(weights);\n  }\n  /**\r\n   * Returns the loss value & metrics values for the model in test mode.\r\n   *\r\n   * Loss and metrics are specified during `compile()`, which needs to happen\r\n   * before calls to `evaluate()`.\r\n   *\r\n   * Computation is done in batches.\r\n   *\r\n   * ```js\r\n   * const model = tf.sequential({\r\n   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\r\n   * });\r\n   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\r\n   * const result = model.evaluate(tf.ones([8, 10]), tf.ones([8, 1]), {\r\n   *   batchSize: 4,\r\n   * });\r\n   * result.print();\r\n   * ```\r\n   *\r\n   * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the\r\n   * model has multiple inputs.\r\n   * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the\r\n   * model has multiple outputs.\r\n   * @param args A `ModelEvaluateConfig`, containing optional fields.\r\n   *\r\n   * @return `Scalar` test loss (if the model has a single output and no\r\n   *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs\r\n   *   and/or metrics). The attribute `model.metricsNames`\r\n   *   will give you the display labels for the scalar outputs.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n  evaluate(x, y, args = {}) {\n    if (!this.built) {\n      throw new RuntimeError('The model needs to be compiled before being used.');\n    }\n    return this.model.evaluate(x, y, args);\n  }\n  // TODO(cais): Add code snippet below once real dataset objects are\n  //   available.\n  /**\r\n   * Evaluate model using a dataset object.\r\n   *\r\n   * Note: Unlike `evaluate()`, this method is asynchronous (`async`);\r\n   *\r\n   * @param dataset A dataset object. Its `iterator()` method is expected\r\n   *   to generate a dataset iterator object, the `next()` method of which\r\n   *   is expected to produce data batches for evaluation. The return value\r\n   *   of the `next()` call ought to contain a boolean `done` field and a\r\n   *   `value` field. The `value` field is expected to be an array of two\r\n   *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\r\n   *   case is for models with exactly one input and one output (e.g..\r\n   *   a sequential model). The latter case is for models with multiple\r\n   *   inputs and/or multiple outputs. Of the two items in the array, the\r\n   *   first is the input feature(s) and the second is the output target(s).\r\n   * @param args A configuration object for the dataset-based evaluation.\r\n   * @returns Loss and metric values as an Array of `Scalar` objects.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n  async evaluateDataset(dataset, args) {\n    if (!this.built) {\n      throw new RuntimeError('The model needs to be compiled before being used.');\n    }\n    return this.model.evaluateDataset(dataset, args);\n  }\n  /**\r\n   * Generates output predictions for the input samples.\r\n   *\r\n   * Computation is done in batches.\r\n   *\r\n   * Note: the \"step\" mode of predict() is currently not supported.\r\n   *   This is because the TensorFow.js core backend is imperative only.\r\n   *\r\n   * ```js\r\n   * const model = tf.sequential({\r\n   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\r\n   * });\r\n   * model.predict(tf.ones([2, 10])).print();\r\n   * ```\r\n   *\r\n   * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if\r\n   *   the model has multiple inputs.\r\n   * @param conifg A `ModelPredictConfig` object containing optional fields.\r\n   *\r\n   * @return `tf.Tensor`(s) of predictions.\r\n   *\r\n   * @exception ValueError In case of mismatch between the provided input data\r\n   *   and the model's expectations, or in case a stateful model receives a\r\n   *   number of samples that is not a multiple of the batch size.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n  predict(x, args = {}) {\n    if (this.model == null) {\n      this.build();\n    }\n    return this.model.predict(x, args);\n  }\n  /**\r\n   * Returns predictions for a single batch of samples.\r\n   *\r\n   * @param x: Input samples, as a Tensor, or list of Tensors (if the model\r\n   *   has multiple inputs).\r\n   * @return Tensor(s) of predictions\r\n   */\n  predictOnBatch(x) {\n    if (this.model == null) {\n      this.build();\n    }\n    return this.model.predictOnBatch(x);\n  }\n  /**\r\n   * See `LayersModel.compile`.\r\n   *\r\n   * @param args\r\n   */\n  compile(args) {\n    this.build();\n    this.model.compile(args);\n    this.optimizer_ = this.model.optimizer;\n    // tslint:disable-next-line:no-any\n    this.isOptimizerOwned = this.model.isOptimizerOwned;\n    this.loss = this.model.loss;\n    this.metrics = this.model.metrics;\n    // TODO(cais): Add this.lossWeights, this.sampleWeightMode,\n    //   this.weightedMetrics, this.targets.\n    this.metricsTensors = this.model.metricsTensors;\n    this.metricsNames = this.model.metricsNames;\n    // TODO(cais): Add sampleWeights.\n  }\n\n  get optimizer() {\n    return this.model == null ? undefined : this.model.optimizer;\n  }\n  set optimizer(optimizer) {\n    this.model.optimizer = optimizer;\n  }\n  /**\r\n   * Trains the model for a fixed number of epochs (iterations on a dataset).\r\n   *\r\n   * ```js\r\n   * const model = tf.sequential({\r\n   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\r\n   * });\r\n   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\r\n   * const history = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {\r\n   *   batchSize: 4,\r\n   *   epochs: 3\r\n   * });\r\n   * console.log(history.history.loss[0]);\r\n   * ```\r\n   *\r\n   * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the\r\n   * model has multiple inputs. If all inputs in the model are named, you can\r\n   * also pass a dictionary mapping input names to `tf.Tensor`s.\r\n   * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if\r\n   * the model has multiple outputs. If all outputs in the model are named, you\r\n   *  can also pass a dictionary mapping output names to `tf.Tensor`s.\r\n   * @param args  A `ModelFitConfig`, containing optional fields.\r\n   *\r\n   * @return A `History` instance. Its `history` attribute contains all\r\n   *   information collected during training.\r\n   *\r\n   * @exception ValueError In case of mismatch between the provided input data\r\n   *   and what the model expects.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n  async fit(x, y, args = {}) {\n    if (!this.built) {\n      throw new RuntimeError('The model needs to be compiled before ' + 'being used.');\n    }\n    return this.model.fit(x, y, args);\n  }\n  /**\r\n   * Trains the model using a dataset object.\r\n   *\r\n   * ```js\r\n   * const xArray = [\r\n   *   [1, 1, 1, 1, 1, 1, 1, 1, 1],\r\n   *   [1, 1, 1, 1, 1, 1, 1, 1, 1],\r\n   *   [1, 1, 1, 1, 1, 1, 1, 1, 1],\r\n   *   [1, 1, 1, 1, 1, 1, 1, 1, 1],\r\n   * ];\r\n   * const yArray = [1, 1, 1, 1];\r\n   * // Create a dataset from the JavaScript array.\r\n   * const xDataset = tf.data.array(xArray);\r\n   * const yDataset = tf.data.array(yArray);\r\n   * // Zip combines the `x` and `y` Datasets into a single Dataset, the\r\n   * // iterator of which will return an object containing of two tensors,\r\n   * // corresponding to `x` and `y`.  The call to `batch(4)` will bundle\r\n   * // four such samples into a single object, with the same keys now pointing\r\n   * // to tensors that hold 4 examples, organized along the batch dimension.\r\n   * // The call to `shuffle(4)` causes each iteration through the dataset to\r\n   * // happen in a different order.  The size of the shuffle window is 4.\r\n   * const xyDataset = tf.data.zip({xs: xDataset, ys: yDataset})\r\n   *     .batch(4)\r\n   *     .shuffle(4);\r\n   * const model = tf.sequential({\r\n   *   layers: [tf.layers.dense({units: 1, inputShape: [9]})]\r\n   * });\r\n   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\r\n   * const history = await model.fitDataset(xyDataset, {\r\n   *   epochs: 4,\r\n   *   callbacks: {onEpochEnd: (epoch, logs) => console.log(logs.loss)}\r\n   * });\r\n   * ```\r\n   *\r\n   * @param dataset A dataset object. Its `iterator()` method is expected to\r\n   *   generate a dataset iterator object, the `next()` method of which is\r\n   *   expected to produce data batches for evaluation. The return value of the\r\n   *   `next()` call ought to contain a boolean `done` field and a `value`\r\n   *   field.\r\n   *\r\n   *   The `value` field is expected to be an object of with fields\r\n   *   `xs` and `ys`, which point to the feature tensor and the target tensor,\r\n   *   respectively. This case is for models with exactly one input and one\r\n   *   output (e.g.. a sequential model). For example:\r\n   *   ```js\r\n   *   {value: {xs: xsTensor, ys: ysTensor}, done: false}\r\n   *   ```\r\n   *\r\n   *   If the model has multiple inputs, the `xs` field of `value` should\r\n   *   be an object mapping input names to their respective feature tensors.\r\n   *   For example:\r\n   *   ```js\r\n   *   {\r\n   *     value: {\r\n   *       xs: {\r\n   *         input_1: xsTensor1,\r\n   *         input_2: xsTensor2\r\n   *       },\r\n   *       ys: ysTensor\r\n   *     },\r\n   *     done: false\r\n   *   }\r\n   *   ```\r\n   *   If the model has multiple outputs, the `ys` field of `value` should\r\n   *   be an object mapping output names to their respective target tensors.\r\n   *   For example:\r\n   *   ```js\r\n   *   {\r\n   *     value: {\r\n   *       xs: xsTensor,\r\n   *       ys: {\r\n   *         output_1: ysTensor1,\r\n   *         output_2: ysTensor2\r\n   *       },\r\n   *     },\r\n   *     done: false\r\n   *   }\r\n   *   ```\r\n   * @param args A `ModelFitDatasetArgs`, containing optional fields.\r\n   *\r\n   * @return A `History` instance. Its `history` attribute contains all\r\n   *   information collected during training.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\r\n   */\n  async fitDataset(dataset, args) {\n    if (!this.built) {\n      throw new RuntimeError('The model needs to be compiled before ' + 'being used.');\n    }\n    return this.model.fitDataset(dataset, args);\n  }\n  /**\r\n   * Runs a single gradient update on a single batch of data.\r\n   *\r\n   * This method differs from `fit()` and `fitDataset()` in the following\r\n   * regards:\r\n   *   - It operates on exactly one batch of data.\r\n   *   - It returns only the loss and matric values, instead of\r\n   *     returning the batch-by-batch loss and metric values.\r\n   *   - It doesn't support fine-grained options such as verbosity and\r\n   *     callbacks.\r\n   *\r\n   * @param x Input data. It could be one of the following:\r\n   *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has\r\n   *     multiple inputs).\r\n   *   - An Object mapping input names to corresponding `tf.Tensor` (if the\r\n   *     model has named inputs).\r\n   * @param y Target darta. It could be either a `tf.Tensor` a multiple\r\n   *   `tf.Tensor`s. It should be consistent with `x`.\r\n   * @returns Training loss or losses (in case the model has\r\n   *   multiple outputs), along with metrics (if any), as numbers.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n  async trainOnBatch(x, y) {\n    return this.model.trainOnBatch(x, y);\n  }\n  /* See parent class for JsDoc */\n  /** @nocollapse */\n  static fromConfig(cls, config, customObjects = {}, fastWeightInit = false) {\n    let configArray;\n    let extraModelConfig = {};\n    if (config instanceof Array) {\n      if (!(config[0].className != null) || config[0]['className'] === 'Merge') {\n        throw new ValueError('Legacy serialization format not supported yet.');\n      }\n      configArray = config;\n    } else {\n      util.assert(config['layers'] != null, () => `When the config data for a Sequential model is not an Array, ` + `it must be an Object that contains the 'layers' field.`);\n      configArray = config['layers'];\n      delete config['layers'];\n      extraModelConfig = config;\n    }\n    const model = new cls(extraModelConfig);\n    if (!(model instanceof Sequential)) {\n      throw new NotImplementedError(`Sequential.fromConfig called on non-Sequential input: ${model}`);\n    }\n    for (const conf of configArray) {\n      const customObjects = undefined;\n      const layer = deserialize(conf, customObjects, fastWeightInit);\n      if (fastWeightInit) {\n        layer.setFastWeightInitDuringBuild(true);\n      }\n      model.add(layer);\n    }\n    return model;\n  }\n  /**\r\n   * Setter used for force stopping of LayersModel.fit() (i.e., training).\r\n   *\r\n   * Example:\r\n   *\r\n   * ```js\r\n   * const model = tf.sequential();\r\n   * model.add(tf.layers.dense({units: 1, inputShape: [10]}));\r\n   * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\r\n   * const xs = tf.ones([8, 10]);\r\n   * const ys = tf.zeros([8, 1]);\r\n   *\r\n   * const history = await model.fit(xs, ys, {\r\n   *   epochs: 10,\r\n   *   callbacks: {\r\n   *     onEpochEnd: async (epoch, logs) => {\r\n   *       if (epoch === 2) {\r\n   *         model.stopTraining = true;\r\n   *       }\r\n   *     }\r\n   *   }\r\n   * });\r\n   *\r\n   * // There should be only 3 values in the loss array, instead of 10 values,\r\n   * // due to the stopping after 3 epochs.\r\n   * console.log(history.history.loss);\r\n   * ```\r\n   */\n  set stopTraining(stop) {\n    // TODO(cais): When refactoring to remove the composition pattern happens,\n    // remove this method overriding.\n    if (this.model == null) {\n      throw new ValueError('Cannot set the stopTraining property of a sequential model before ' + 'it is compiled.');\n    }\n    this.model.stopTraining = stop;\n  }\n  get stopTraining() {\n    if (this.model == null) {\n      throw new ValueError('Cannot get the stopTraining property of a sequential model before ' + 'it is compiled.');\n    }\n    return this.model.stopTraining;\n  }\n  // TODO(cais): Override get trainableWeights() here\n  // tslint:disable-next-line:no-any\n  getConfig() {\n    // NOTE(cais): We override the return type of getConfig() to `any` here,\n    //   because the `Sequential` class is a special case among `Container`\n    //   subtypes in that its getConfig() method returns an Array (not a\n    //   dict).\n    const layers = [];\n    for (const layer of this.layers) {\n      const dict = {};\n      dict['className'] = layer.getClassName();\n      dict['config'] = layer.getConfig();\n      layers.push(dict);\n    }\n    return {\n      name: this.name,\n      layers\n    };\n  }\n}\n/** @nocollapse */\nSequential.className = 'Sequential';\nserialization.registerClass(Sequential);","map":null,"metadata":{},"sourceType":"module"}